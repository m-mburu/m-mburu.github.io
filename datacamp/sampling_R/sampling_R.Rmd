---
title: "Sampling in R"
date: "2022-09-09"
output: 
  html_document:
    theme: lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Reasons for sampling

Sampling is an important technique in your statistical arsenal. It isn't always appropriate though---you need to know when to use it and when to work with the whole dataset.

-   Which of the following is not a good scenario to use sampling?
-   when data set is small

## Simple sampling with dplyr

Throughout this chapter you'll be exploring song data from Spotify. Each row of the dataset represents a song, and there are 41656 rows. Columns include the name of the song, the artists who performed it, the release year, and attributes of the song like its duration, tempo, and danceability. We'll start by looking at the durations.

Your first task is to sample the song dataset and compare a calculation on the whole population and on a sample.

spotify_population is available and dplyr is loaded.

```{r}
library(tidyverse)
library(fst)
library(knitr)
spotify_population <- read_fst("data/spotify_2000_2020.fst")
# View the whole population dataset

# Sample 1000 rows from spotify_population
spotify_sample <- slice_sample(spotify_population, n = 10)


# See the result
kable(spotify_sample)
```

## Simple sampling with dplyr

Throughout this chapter you'll be exploring song data from Spotify. Each row of the dataset represents a song, and there are 41656 rows. Columns include the name of the song, the artists who performed it, the release year, and attributes of the song like its duration, tempo, and danceability. We'll start by looking at the durations.

Your first task is to sample the song dataset and compare a calculation on the whole population and on a sample.

spotify_population is available and dplyr is loaded.

```{r}
# Calculate the mean duration in mins from spotify_population
mean_dur_pop <- summarize(spotify_population, mean(duration_minutes))


# Calculate the mean duration in mins from spotify_sample
mean_dur_samp <- summarize(spotify_sample, mean(duration_minutes))


# See the results
mean_dur_pop
mean_dur_samp
```

## Simple sampling with base-R

While dplyr provides great tools for sampling data frames, if you want to work with vectors you can use base-R.

Let's turn it up to eleven and look at the loudness property of each song.

spotify_population is available.

```{r}
# From previous step
loudness_pop <- spotify_population$loudness
loudness_samp <- sample(loudness_pop, size = 100)

# Calculate the standard deviation of loudness_pop
sd_loudness_pop <- sd(loudness_pop)

# Calculate the standard deviation of loudness_samp
sd_loudness_samp <- sd(loudness_samp)

# See the results
sd_loudness_pop
sd_loudness_samp
```

## Are findings from the sample generalizable?

You just saw how convenience sampling---collecting data via the easiest method can result in samples that aren't representative of the whole population. Equivalently, this means findings from the sample are not generalizable to the whole population. Visualizing the distributions of the population and the sample can help determine whether or not the sample is representative of the population.

The Spotify dataset contains a column named acousticness, which is a confidence measure from zero to one of whether the track is acoustic, that is, it was made with instruments that aren't plugged in. Here, you'll look at acousticness in the total population of songs, and in a sample of those songs.

spotify_population and spotify_mysterious_sample are available; dplyr and ggplot2 are loaded.

```{r}
ggplot(spotify_population, aes(acousticness))+
    geom_histogram(binwidth = 0.01)
```

```{r}

ggplot(spotify_population, aes(duration_minutes))+
    geom_histogram(binwidth = 0.5)
    
```

## Generating random numbers

You've seen sample() and it's dplyr cousin, slice_sample() for generating pseudo-random numbers from a set of values. A related task is to generate random numbers that follow a statistical distribution, like the uniform distribution or the normal distribution.

Each random number generation function has a name beginning with "r". It's first argument is the number of numbers to generate, but other arguments are distribution-specific. Free hint: Try args(runif) and args(rnorm) to see what arguments you need to pass to those functions.

n_numbers is available and set to 5000; ggplot2 is loaded.

```{r}
n_numbers <- 5000
# Generate random numbers from ...
randoms <- data.frame(
  # a uniform distribution from -3 to 3
  uniform =runif(n_numbers, -3, 3),
  # a normal distribution with mean 5 and sd 2
  normal = rnorm(n_numbers, mean = 5, sd = 2)
)


# Plot a histogram of uniform values, binwidth 0.25
ggplot(randoms, aes(uniform)) +
    geom_histogram(binwidth = 0.25)

# Plot a histogram of normal values, binwidth 0.5
ggplot(randoms, aes(normal)) +
    geom_histogram(binwidth = 0.5)
```

## Understanding random seeds

While random numbers are important for many analyses, they create a problem: the results you get can vary slightly. This can cause awkward conversations with your boss when your script for calculating the sales forecast gives different answers each time.

Setting the seed to R's random number generator helps avoid such problems by making the random number generation reproducible. - The values of x are different to those of y.

```{r}
set.seed(123)
x <- rnorm(5)
y <- rnorm(5)
x
y
```

-   x and y have identical values.

```{r}
set.seed(123)
x <- rnorm(5)
set.seed(123)
y <- rnorm(5)
x
y
```

-   x and y have identical values.

```{r}
set.seed(123)
x <- c(rnorm(5), rnorm(5))
set.seed(123)
y <- rnorm(10)
x
y
```
