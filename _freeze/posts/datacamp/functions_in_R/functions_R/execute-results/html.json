{
  "hash": "e7d6c626dd907ff414eb38753eafc35d",
  "result": {
    "markdown": "---\ntitle: \"Functions in R\"\noutput: github_document\n---\n\n\n\n\n## Calling functions\n\nOne way to make your code more readable is to be careful about the order you pass arguments when you call functions, and whether you pass the arguments by position or by name.\n\ngold_medals, a numeric vector of the number of gold medals won by each country in the 2016 Summer Olympics, is provided.\n\nFor convenience, the arguments of median() and rank() are displayed using args(). Setting rank()'s na.last argument to \"keep\" means \"keep the rank of NA values as NA\".\n\nBest practice for calling functions is to include them in the order shown by args(), and to only name rare arguments.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngd_nms <-  c(\"USA\", \"GBR\", \"CHN\", \"RUS\", \"GER\", \"JPN\", \"FRA\", \"KOR\", \"ITA\", \n            \"AUS\", \"NED\", \"HUN\", \"BRA\", \"ESP\", \"KEN\", \"JAM\", \"CRO\", \"CUB\", \n            \"NZL\", \"CAN\", \"UZB\", \"KAZ\", \"COL\", \"SUI\", \"IRI\", \"GRE\", \"ARG\", \n            \"DEN\", \"SWE\", \"RSA\", \"UKR\", \"SRB\", \"POL\", \"PRK\", \"BEL\", \"THA\", \n            \"SVK\", \"GEO\", \"AZE\", \"BLR\", \"TUR\", \"ARM\", \"CZE\", \"ETH\", \"SLO\", \n            \"INA\", \"ROU\", \"BRN\", \"VIE\", \"TPE\", \"BAH\", \"IOA\", \"CIV\", \"FIJ\", \n            \"JOR\", \"KOS\", \"PUR\", \"SIN\", \"TJK\", \"MAS\", \"MEX\", \"VEN\", \"ALG\", \n            \"IRL\", \"LTU\", \"BUL\", \"IND\", \"MGL\", \"BDI\", \"GRN\", \"NIG\", \"PHI\", \n            \"QAT\", \"NOR\", \"EGY\", \"TUN\", \"ISR\", \"AUT\", \"DOM\", \"EST\", \"FIN\", \n            \"MAR\", \"NGR\", \"POR\", \"TTO\", \"UAE\", \"IOC\")\n\ngold_medals <- c(46L, 27L, 26L, 19L, 17L, 12L, 10L, 9L, 8L, 8L, 8L, 8L, 7L, \n                 7L, 6L, 6L, 5L, 5L, 4L, 4L,4L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, \n                 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L,\n                 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,\n                 1L, 1L, 1L, 1L, 0L,0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n                 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,\n                 0L, 0L, 0L, 0L, 0L, 0L, NA)\n\nnames(gold_medals) <- gd_nms\n\ngold_medals\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUSA GBR CHN RUS GER JPN FRA KOR ITA AUS NED HUN BRA ESP KEN JAM CRO CUB NZL CAN \n 46  27  26  19  17  12  10   9   8   8   8   8   7   7   6   6   5   5   4   4 \nUZB KAZ COL SUI IRI GRE ARG DEN SWE RSA UKR SRB POL PRK BEL THA SVK GEO AZE BLR \n  4   3   3   3   3   3   3   2   2   2   2   2   2   2   2   2   2   2   1   1 \nTUR ARM CZE ETH SLO INA ROU BRN VIE TPE BAH IOA CIV FIJ JOR KOS PUR SIN TJK MAS \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0 \nMEX VEN ALG IRL LTU BUL IND MGL BDI GRN NIG PHI QAT NOR EGY TUN ISR AUT DOM EST \n  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \nFIN MAR NGR POR TTO UAE IOC \n  0   0   0   0   0   0  NA \n```\n:::\n\n```{.r .cell-code}\n# Note the arguments to median()\nargs(median)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (x, na.rm = FALSE, ...) \nNULL\n```\n:::\n\n```{.r .cell-code}\n# Rewrite this function call, following best practices\nmedian(gold_medals, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\n# Note the arguments to rank()\nargs(rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (x, na.last = TRUE, ties.method = c(\"average\", \"first\", \n    \"last\", \"random\", \"max\", \"min\")) \nNULL\n```\n:::\n\n```{.r .cell-code}\n# Rewrite this function call, following best practices\n\nrank(-gold_medals, na.last = \"keep\", ties.method=  \"min\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUSA GBR CHN RUS GER JPN FRA KOR ITA AUS NED HUN BRA ESP KEN JAM CRO CUB NZL CAN \n  1   2   3   4   5   6   7   8   9   9   9   9  13  13  15  15  17  17  19  19 \nUZB KAZ COL SUI IRI GRE ARG DEN SWE RSA UKR SRB POL PRK BEL THA SVK GEO AZE BLR \n 19  22  22  22  22  22  22  28  28  28  28  28  28  28  28  28  28  28  39  39 \nTUR ARM CZE ETH SLO INA ROU BRN VIE TPE BAH IOA CIV FIJ JOR KOS PUR SIN TJK MAS \n 39  39  39  39  39  39  39  39  39  39  39  39  39  39  39  39  39  39  39  60 \nMEX VEN ALG IRL LTU BUL IND MGL BDI GRN NIG PHI QAT NOR EGY TUN ISR AUT DOM EST \n 60  60  60  60  60  60  60  60  60  60  60  60  60  60  60  60  60  60  60  60 \nFIN MAR NGR POR TTO UAE IOC \n 60  60  60  60  60  60  NA \n```\n:::\n:::\n\n\n## Your first function: tossing a coin\n\nTime to write your first function! It's a really good idea when writing functions to start simple. You can always make a function more complicated later if it's really necessary, so let's not worry about arguments for now.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoin_sides <- c(\"head\", \"tail\")\n\n# Sample from coin_sides once\nsample(coin_sides, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"head\"\n```\n:::\n\n```{.r .cell-code}\n# Your functions, from previous steps\ntoss_coin <- function() {\n  coin_sides <- c(\"head\", \"tail\")\n  sample(coin_sides, 1)\n}\n\n# Call your function\ntoss_coin()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"tail\"\n```\n:::\n:::\n\n\n## Inputs to functions\n\nMost functions require some sort of input to determine what to compute. The inputs to functions are called arguments. You specify them inside the parentheses after the word \"function.\"\n\nAs mentioned in the video, the following exercises assume that you are using sample() to do random sampling.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Update the function to return n coin tosses\ntoss_coin <- function(n_flips) {\n  coin_sides <- c(\"head\", \"tail\")\n  sample(coin_sides, n_flips, replace = TRUE)\n}\n\n# Generate 10 coin tosses\ntoss_coin(1000) %>% table() %>% prop.table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n head  tail \n0.477 0.523 \n```\n:::\n:::\n\n\n## Multiple inputs to functions\n\nIf a function should have more than one argument, list them in the function signature, separated by commas. To solve this exercise, you need to know how to specify sampling weights to sample(). Set the prob argument to a numeric vector with the same length as x. Each value of prob is the probability of sampling the corresponding element of x, so their values add up to one. In the following example, each sample has a 20% chance of \"bat\", a 30% chance of \"cat\" and a 50% chance of \"rat\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Update the function so heads have probability p_head\ntoss_coin <- function(n_flips, p_head) {\n  coin_sides <- c(\"head\", \"tail\")\n  # Define a vector of weights\n  weights <- c(p_head,1- p_head)\n  # Modify the sampling to be weighted\n  sample(coin_sides, n_flips, replace = TRUE, prob = weights)\n}\n\n# Generate 10 coin tosses\ntoss_coin(10,p_head=.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"head\" \"head\" \"head\" \"head\" \"head\" \"head\" \"tail\" \"tail\" \"tail\" \"head\"\n```\n:::\n:::\n\n\n## Data or detail?\n\nRecall that data arguments are what a function computes on, and detail arguments advise on how the computation should be performed. Each of the arguments to t.test() is shown, along with a brief description of it.\n\n## Renaming GLM\n\nR's generalized linear regression function, glm(), suffers the same usability problems as lm(): its name is an acronym, and its formula and data arguments are in the wrong order. To solve this exercise, you need to know two things about generalized linear regression: glm() formulas are specified like lm() formulas: response is on the left, and explanatory variables are added on the right. To model count data, set glm()'s family argument to poisson, making it a Poisson regression. Here you'll use data on the number of yearly visits to Snake River at Jackson Hole, Wyoming, snake_river_visits.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsnake_river_visits <-read_rds(\"snake_river_visits.rds\")\n# From previous step\nrun_poisson_regression <- function(data, formula) {\n  glm(formula, data, family = poisson)\n}\n\n# Re-run the Poisson regression, using your function\nmodel <- snake_river_visits %>%\n  run_poisson_regression(n_visits ~ gender + income + travel)\n\n# Run this to see the predictions\nsnake_river_visits %>%\n  mutate(predicted_n_visits = predict(model, ., type = \"response\"))%>%\n  arrange(desc(predicted_n_visits)) %>%\n    head() %>% kable()\n```\n\n::: {.cell-output-display}\n| n_visits|gender |income    |travel     | predicted_n_visits|\n|--------:|:------|:---------|:----------|------------------:|\n|       80|female |[$0,$25k] |[0h,0.25h] |            86.5186|\n|       35|female |[$0,$25k] |[0h,0.25h] |            86.5186|\n|       50|female |[$0,$25k] |[0h,0.25h] |            86.5186|\n|      125|female |[$0,$25k] |[0h,0.25h] |            86.5186|\n|       24|female |[$0,$25k] |[0h,0.25h] |            86.5186|\n|      100|female |[$0,$25k] |[0h,0.25h] |            86.5186|\n:::\n:::\n\n\n## Numeric defaults\n\ncut_by_quantile() converts a numeric vector into a categorical variable where quantiles define the cut points. This is a useful function, but at the moment you have to specify five arguments to make it work. This is too much thinking and typing. By specifying default arguments, you can make it easier to use. Let's start with n, which specifies how many categories to cut x into.A numeric vector of the number of visits to Snake River is provided as n_visits.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the default for n to 5\nn_visits = snake_river_visits$n_visits\ncut_by_quantile <- function(x, n=5, na.rm, labels, interval_type) {\n  probs <- seq(0, 1, length.out = n + 1)\n  qtiles <- quantile(x, probs, na.rm = na.rm, names = FALSE)\n  right <- switch(interval_type, \"(lo, hi]\" = TRUE, \"[lo, hi)\" = FALSE)\n  cut(x, qtiles, labels = labels, right = right, include.lowest = TRUE)\n}\n\n# Remove the n argument from the call\ncut_by_quantile(\n  n_visits, \n  na.rm = FALSE, \n  labels = c(\"very low\", \"low\", \"medium\", \"high\", \"very high\"),\n  interval_type = \"(lo, hi]\"\n) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] very low very low very low very low very low very low\nLevels: very low low medium high very high\n```\n:::\n:::\n\n\n## Logical defaults\n\ncut_by_quantile() is now slightly easier to use, but you still always have to specify the na.rm argument. This removes missing values -- it behaves the same as the na.rm argument to mean() or sd().\n\nWhere functions have an argument for removing missing values, the best practice is to not remove them by default (in case you hadn't spotted that you had missing values). That means that the default for na.rm should be FALSE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the default for na.rm to FALSE\ncut_by_quantile <- function(x, n = 5, na.rm = FALSE, labels, interval_type) {\n  probs <- seq(0, 1, length.out = n + 1)\n  qtiles <- quantile(x, probs, na.rm = na.rm, names = FALSE)\n  right <- switch(interval_type, \"(lo, hi]\" = TRUE, \"[lo, hi)\" = FALSE)\n  cut(x, qtiles, labels = labels, right = right, include.lowest = TRUE)\n}\n\n# Remove the na.rm argument from the call\ncut_by_quantile(\n  n_visits, \n  labels = c(\"very low\", \"low\", \"medium\", \"high\", \"very high\"),\n  interval_type = \"(lo, hi]\"\n) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] very low very low very low very low very low very low\nLevels: very low low medium high very high\n```\n:::\n:::\n\n\n## NULL defaults\n\nThe cut() function used by cut_by_quantile() can automatically provide sensible labels for each category. The code to generate these labels is pretty complicated, so rather than appearing in the function signature directly, its labels argument defaults to NULL, and the calculation details are shown on the ?cut help page.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the default for labels to NULL\ncut_by_quantile <- function(x, n = 5, na.rm = FALSE, labels=NULL, interval_type) {\n  probs <- seq(0, 1, length.out = n + 1)\n  qtiles <- quantile(x, probs, na.rm = na.rm, names = FALSE)\n  right <- switch(interval_type, \"(lo, hi]\" = TRUE, \"[lo, hi)\" = FALSE)\n  cut(x, qtiles, labels = labels, right = right, include.lowest = TRUE)\n}\n\n# Remove the labels argument from the call\ncut_by_quantile(\n  n_visits,\n  #labels = c(\"very low\", \"low\", \"medium\", \"high\", \"very high\"),\n  interval_type = \"(lo, hi]\"\n) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] [0,1] [0,1] [0,1] [0,1] [0,1] [0,1]\nLevels: [0,1] (1,2] (2,10] (10,35] (35,350]\n```\n:::\n:::\n\n\n## Categorical defaults\n\nWhen cutting up a numeric vector, you need to worry about what happens if a value lands exactly on a boundary. You can either put this value into a category of the lower interval or the higher interval. That is, you can choose your intervals to include values at the top boundary but not the bottom (in mathematical terminology, \"open on the left, closed on the right\", or (lo, hi\\]). Or you can choose the opposite (\"closed on the left, open on the right\", or \\[lo, hi)). cut_by_quantile() should allow these two choices.\n\nThe pattern for categorical defaults is:\n\nfunction(cat_arg = c(\"choice1\", \"choice2\")) { cat_arg \\<- match.arg(cat_arg) }\n\nFree hint: In the console, type head(rank) to see the start of rank()'s definition, and look at the ties.method argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the categories for interval_type to \"(lo, hi]\" and \"[lo, hi)\"\ncut_by_quantile <- function(x, n = 5, na.rm = FALSE, labels = NULL, \n                            interval_type= c(\"(lo, hi]\", \"[lo, hi)\")) {\n  # Match the interval_type argument\n  interval_type <- match.arg(interval_type)\n  probs <- seq(0, 1, length.out = n + 1)\n  qtiles <- quantile(x, probs, na.rm = na.rm, names = FALSE)\n  right <- switch(interval_type, \"(lo, hi]\" = TRUE, \"[lo, hi)\" = FALSE)\n  cut(x, qtiles, labels = labels, right = right, include.lowest = TRUE)\n}\n\n# Remove the interval_type argument from the call\ncut_by_quantile(n_visits) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] [0,1] [0,1] [0,1] [0,1] [0,1] [0,1]\nLevels: [0,1] (1,2] (2,10] (10,35] (35,350]\n```\n:::\n:::\n\n\n## Harmonic mean\n\nThe harmonic mean is the reciprocal of the arithmetic mean of the reciprocal of the data. That is\n\nThe harmonic mean is often used to average ratio data. You'll be using it on the price/earnings ratio of stocks in the Standard and Poor's 500 index, provided as std_and_poor500. Price/earnings ratio is a measure of how expensive a stock is.\n\nThe dplyr package is loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstd_and_poor500 <- read_rds(\"std_and_poor500_with_pe_2019-06-21.rds\")\n# Look at the Standard and Poor 500 data\nglimpse(std_and_poor500)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 505\nColumns: 5\n$ symbol   <chr> \"MMM\", \"ABT\", \"ABBV\", \"ABMD\", \"ACN\", \"ATVI\", \"ADBE\", \"AMD\", \"…\n$ company  <chr> \"3M Company\", \"Abbott Laboratories\", \"AbbVie Inc.\", \"ABIOMED …\n$ sector   <chr> \"Industrials\", \"Health Care\", \"Health Care\", \"Health Care\", \"…\n$ industry <chr> \"Industrial Conglomerates\", \"Health Care Equipment\", \"Pharmac…\n$ pe_ratio <dbl> 18.31678, 57.66621, 22.43805, 45.63993, 27.00233, 20.13596, 5…\n```\n:::\n\n```{.r .cell-code}\n# Write a function to calculate the reciprocal\n# From previous steps\nget_reciprocal <- function(x) {\n  1 / x\n}\ncalc_harmonic_mean <- function(x) {\n  x %>%\n    get_reciprocal() %>%\n    mean() %>%\n    get_reciprocal()\n}\n\nstd_and_poor500 %>% \n  # Group by sector\n  group_by(sector) %>% \n  # Summarize, calculating harmonic mean of P/E ratio\n  summarise(hmean_pe_ratio = calc_harmonic_mean(pe_ratio))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 × 2\n   sector                 hmean_pe_ratio\n   <chr>                           <dbl>\n 1 Communication Services           NA  \n 2 Consumer Discretionary           NA  \n 3 Consumer Staples                 NA  \n 4 Energy                           NA  \n 5 Financials                       NA  \n 6 Health Care                      NA  \n 7 Industrials                      NA  \n 8 Information Technology           NA  \n 9 Materials                        NA  \n10 Real Estate                      32.5\n11 Utilities                        NA  \n```\n:::\n:::\n\n\n## Dealing with missing values\n\nIn the last exercise, many sectors had an NA value for the harmonic mean. It would be useful for your function to be able to remove missing values before calculating.\n\nRather than writing your own code for this, you can outsource this functionality to mean().\n\nThe dplyr package is loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# From previous step\ncalc_harmonic_mean <- function(x, na.rm = FALSE) {\n  x %>%\n    get_reciprocal() %>%\n    mean(na.rm = na.rm) %>%\n    get_reciprocal()\n}\n\nstd_and_poor500 %>% \n  # Group by sector\n  group_by(sector) %>% \n  # Summarize, calculating harmonic mean of P/E ratio\n  summarise(hmean_pe_ratio = calc_harmonic_mean(pe_ratio, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 × 2\n   sector                 hmean_pe_ratio\n   <chr>                           <dbl>\n 1 Communication Services           17.5\n 2 Consumer Discretionary           15.2\n 3 Consumer Staples                 19.8\n 4 Energy                           13.7\n 5 Financials                       12.9\n 6 Health Care                      26.6\n 7 Industrials                      18.2\n 8 Information Technology           21.6\n 9 Materials                        16.3\n10 Real Estate                      32.5\n11 Utilities                        23.9\n```\n:::\n:::\n\n\n## Passing arguments with ...\n\nRather than explicitly giving calc_harmonic_mean() and na.rm argument, you can use ... to simply \"pass other arguments\" to mean().\n\nThe dplyr package is loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_harmonic_mean <- function(x, ...) {\n  x %>%\n    get_reciprocal() %>%\n    mean(...) %>%\n    get_reciprocal()\n}\n\n\nstd_and_poor500 %>% \n  # Group by sector\n  group_by(sector) %>% \n  # Summarize, calculating harmonic mean of P/E ratio\n  summarise(hmean_pe_ratio = calc_harmonic_mean(pe_ratio, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 × 2\n   sector                 hmean_pe_ratio\n   <chr>                           <dbl>\n 1 Communication Services           17.5\n 2 Consumer Discretionary           15.2\n 3 Consumer Staples                 19.8\n 4 Energy                           13.7\n 5 Financials                       12.9\n 6 Health Care                      26.6\n 7 Industrials                      18.2\n 8 Information Technology           21.6\n 9 Materials                        16.3\n10 Real Estate                      32.5\n11 Utilities                        23.9\n```\n:::\n:::\n\n\n## Throwing errors with bad arguments\n\nIf a user provides a bad input to a function, the best course of action is to throw an error letting them know. The two rules are\n\nThrow the error message as soon as you realize there is a problem (typically at the start of the function). Make the error message easily understandable. You can use the assert\\_\\*() functions from assertive to check inputs and throw errors when they fail.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(assertive)\ncalc_harmonic_mean <- function(x, na.rm = FALSE) {\n  # Assert that x is numeric\n  assert_is_numeric(x)\n  x %>%\n    get_reciprocal() %>%\n    mean(na.rm = na.rm) %>%\n    get_reciprocal()\n}\n\n# See what happens when you pass it strings\n#calc_harmonic_mean(std_and_poor500$sector)\n```\n:::\n\n\n## Custom error logic\n\nSometimes the assert\\_\\*() functions in assertive don't give the most informative error message. For example, the assertions that check if a number is in a numeric range will tell the user that a value is out of range, but the won't say why that's a problem. In that case, you can use the is\\_\\*() functions in conjunction with messages, warnings, or errors to define custom feedback.\n\nThe harmonic mean only makes sense when x has all positive values. (Try calculating the harmonic mean of one and minus one to see why.) Make sure your users know this!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_harmonic_mean <- function(x, na.rm = FALSE) {\n  assert_is_numeric(x)\n  # Check if any values of x are non-positive\n  if(any(is_non_positive(x), na.rm = TRUE)) {\n    # Throw an error\n    stop(\"x contains non-positive values, so the harmonic mean makes no sense.\")\n  }\n  x %>%\n    get_reciprocal() %>%\n    mean(na.rm = na.rm) %>%\n    get_reciprocal()\n}\n\n# See what happens when you pass it negative numbers\n#calc_harmonic_mean(std_and_poor500$pe_ratio - 20)\n```\n:::\n\n\n## Fixing function arguments\n\nThe harmonic mean function is almost complete. However, you still need to provide some checks on the na.rm argument. This time, rather than throwing errors when the input is in an incorrect form, you are going to try to fix it.\n\nna.rm should be a logical vector with one element (that is, TRUE, or FALSE).\n\nThe assertive package is loaded for you.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Update the function definition to fix the na.rm argument\ncalc_harmonic_mean <- function(x, na.rm = FALSE) {\n  assert_is_numeric(x)\n  if(any(is_non_positive(x), na.rm = TRUE)) {\n    stop(\"x contains non-positive values, so the harmonic mean makes no sense.\")\n  }\n  # Use the first value of na.rm, and coerce to logical\n  na.rm <- coerce_to(use_first(na.rm), target_class = \"logical\")\n  x %>%\n    get_reciprocal() %>%\n    mean(na.rm = na.rm) %>%\n    get_reciprocal()\n}\n\n# See what happens when you pass it malformed na.rm\ncalc_harmonic_mean(std_and_poor500$pe_ratio, na.rm = 1:5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.23871\n```\n:::\n:::\n\n\n## Returning early\n\nSometimes, you don't need to run through the whole body of a function to get the answer. In that case you can return early from that function using return().\n\nTo check if x is divisible by n, you can use is_divisible_by(x, n) from assertive.\n\nAlternatively, use the modulo operator, %%. x %% n gives the remainder when dividing x by n, so x %% n == 0 determines whether x is divisible by n. Try 1:10 %% 3 == 0 in the console.\n\nTo solve this exercise, you need to know that a leap year is every 400th year (like the year 2000) or every 4th year that isn't a century (like 1904 but not 1900 or 1905).\n\nassertive is loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis_leap_year <- function(year) {\n  # If year is div. by 400 return TRUE\n  if(is_divisible_by(year, 400)) {\n    return(TRUE)\n  }\n  # If year is div. by 100 return FALSE\n  if(is_divisible_by(year, 100)) {\n    return(FALSE)\n  }  \n  # If year is div. by 4 return TRUE\n   if(is_divisible_by(year, 4)) {\n    return(TRUE)\n  \n  \n  \n  # Otherwise return FALSE\n   } else return(FALSE)\n}\nis_leap_year(year = 1900)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\n## Returning invisibly\n\nWhen the main purpose of a function is to generate output, like drawing a plot or printing something in the console, you may not want a return value to be printed as well. In that case, the value should be invisibly returned.\n\nThe base R plot function returns NULL, since its main purpose is to draw a plot. This isn't helpful if you want to use it in piped code: instead it should invisibly return the plot data to be piped on to the next step.\n\nRecall that plot() has a formula interface: instead of giving it vectors for x and y, you can specify a formula describing which columns of a data frame go on the x and y axes, and a data argument for the data frame. Note that just like lm(), the arguments are the wrong way round because the detail argument, formula, comes before the data argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using cars, draw a scatter plot of dist vs. speed\nplt_dist_vs_speed <- plot(dist ~ speed, data = cars)\n\n# Oh no! The plot object is NULL\nplt_dist_vs_speed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n```{.r .cell-code}\n# Define a pipeable plot fn with data and formula args\npipeable_plot <- function(data, formula) {\n  # Call plot() with the formula interface\n  plot(formula, data)\n  # Invisibly return the input dataset\n  invisible(head(data))\n}\n\n# Draw the scatter plot of dist vs. speed again\nplt_dist_vs_speed <- cars %>% \n  pipeable_plot(dist ~ speed)\n```\n\n::: {.cell-output-display}\n![](functions_R_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Now the plot object has a value\nplt_dist_vs_speed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  speed dist\n1     4    2\n2     4   10\n3     7    4\n4     7   22\n5     8   16\n6     9   10\n```\n:::\n:::\n\n\n## Returning many things\n\nFunctions can only return one value. If you want to return multiple things, then you can store them all in a list.\n\nIf users want to have the list items as separate variables, they can assign each list element to its own variable using zeallot's multi-assignment operator, %\\<-%.\n\nglance(), tidy(), and augment() each take the model object as their only argument.\n\nThe Poisson regression model of Snake River visits is available as model. broom and zeallot are loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(zeallot)\nlibrary(broom)\nmodel <- glm(n_visits ~ gender + income + travel, \n             data =snake_river_visits )\n# From previous step\ngroom_model <- function(model) {\n  list(\n    model = glance(model),\n    coefficients = tidy(model),\n    observations = augment(model)\n  )\n}\n\n# Call groom_model on model, assigning to 3 variables\n\nc(mdl, cff,  obs) %<-% groom_model(model)\n\n# See these individual variables\nmdl; cff; obs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1       820296.     345 -1791. 3599. 3630.  636485.         339   346\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)          61.5       7.83     7.86  5.06e-14\n2 genderfemale         10.8       4.94     2.19  2.88e- 2\n3 income($25k,$55k]    -1.95      7.74    -0.251 8.02e- 1\n4 income($55k,$95k]   -19.3       8.01    -2.42  1.63e- 2\n5 income($95k,$Inf)   -18.6       7.47    -2.49  1.32e- 2\n6 travel(0.25h,4h]    -26.6       6.00    -4.44  1.24e- 5\n7 travel(4h,Infh)     -45.1       6.30    -7.16  5.06e-12\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 346 × 11\n   .rownames n_visits gender income  travel .fitted .resid .std.…¹   .hat .sigma\n   <chr>        <dbl> <fct>  <fct>   <fct>    <dbl>  <dbl>   <dbl>  <dbl>  <dbl>\n 1 25               2 female ($95k,… (4h,I…    8.67  -6.67 -0.155  0.0179   43.4\n 2 26               1 female ($95k,… (4h,I…    8.67  -7.67 -0.179  0.0179   43.4\n 3 27               1 male   ($95k,… (0.25…   16.3  -15.3  -0.357  0.0153   43.4\n 4 29               1 male   ($95k,… (4h,I…   -2.18   3.18  0.0738 0.0122   43.4\n 5 30               1 female ($55k,… (4h,I…    7.95  -6.95 -0.162  0.0229   43.4\n 6 31               1 male   [$0,$2… [0h,0…   61.5  -60.5  -1.42   0.0326   43.3\n 7 33              80 female [$0,$2… [0h,0…   72.4    7.61  0.178  0.0291   43.4\n 8 34             104 female ($95k,… [0h,0…   53.8   50.2   1.17   0.0215   43.3\n 9 35              55 male   ($25k,… (0.25…   33.0   22.0   0.512  0.0165   43.4\n10 36             350 female ($25k,… [0h,0…   70.4  280.    6.52   0.0215   40.6\n# … with 336 more rows, 1 more variable: .cooksd <dbl>, and abbreviated\n#   variable name ¹​.std.resid\n```\n:::\n:::\n\n\n## Returning metadata\n\nSometimes you want the return multiple things from a function, but you want the result to have a particular class (for example, a data frame or a numeric vector), so returning a list isn't appropriate. This is common when you have a result plus metadata about the result. (Metadata is \"data about the data\". For example, it could be the file a dataset was loaded from, or the username of the person who created the variable, or the number of iterations for an algorithm to converge.)\n\nIn that case, you can store the metadata in attributes. Recall the syntax for assigning attributes is as follows.\n\nattr(object, \"attribute_name\") \\<- attribute_value\n\n\n::: {.cell}\n\n```{.r .cell-code}\npipeable_plot <- function(data, formula) {\n  plot(formula, data)\n  # Add a \"formula\" attribute to data\n  attr(data, \"formula\") <- formula\n  \n  invisible(data)\n}\n\n# From previous exercise\nplt_dist_vs_speed <- cars %>% \n  pipeable_plot(dist ~ speed)\n```\n\n::: {.cell-output-display}\n![](functions_R_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Examine the structure of the result\nplt_dist_vs_speed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n```\n:::\n:::\n\n\n## Creating and exploring environments\n\nEnvironments are used to store other variables. Mostly, you can think of them as lists, but there's an important extra property that is relevant to writing functions. Every environment has a parent environment (except the empty environment, at the root of the environment tree). This determines which variables R know about at different places in your code.\n\nFacts about the Republic of South Africa are contained in capitals, national_parks, and population.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# From previous steps\nrsa_lst <- list(\n  capitals = c(\"J Burg\", \"Capetown\"),\n  national_parks = c(\"Krug\", \"Iddo\"),\n  population = 30000\n)\nrsa_env <- list2env(rsa_lst)\n\n# Find the parent environment of rsa_env\nparent <- parent.env(rsa_env)\n\n# Print its name\nenvironmentName(parent)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"R_GlobalEnv\"\n```\n:::\n:::\n\n\nDo variables exist? If R cannot find a variable in the current environment, it will look in the parent environment, then the grandparent environment, and so on until it finds it.\n\nrsa_env has been modified so it includes capitals and national_parks, but not population.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare the contents of the global environment and rsa_env\nls.str(globalenv())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncalc_harmonic_mean : function (x, na.rm = FALSE)  \ncff : tibble [7 × 5] (S3: tbl_df/tbl/data.frame)\ncoin_sides :  chr [1:2] \"head\" \"tail\"\ncut_by_quantile : function (x, n = 5, na.rm = FALSE, labels = NULL, interval_type = c(\"(lo, hi]\", \n    \"[lo, hi)\"))  \ngd_nms :  chr [1:87] \"USA\" \"GBR\" \"CHN\" \"RUS\" \"GER\" \"JPN\" \"FRA\" \"KOR\" \"ITA\" \"AUS\" ...\nget_reciprocal : function (x)  \ngold_medals :  Named int [1:87] 46 27 26 19 17 12 10 9 8 8 ...\ngroom_model : function (model)  \nis_leap_year : function (year)  \nmdl : tibble [1 × 8] (S3: tbl_df/tbl/data.frame)\nmodel : List of 31\n $ coefficients     : Named num [1:7] 61.54 10.85 -1.95 -19.33 -18.62 ...\n $ residuals        : Named num [1:346] -6.67 -7.67 -15.33 3.18 -6.95 ...\n $ fitted.values    : Named num [1:346] 8.67 8.67 16.33 -2.18 7.95 ...\n $ effects          : Named num [1:346] -509.9 -174.8 167.5 -46.6 162.4 ...\n $ R                : num [1:7, 1:7] -18.6 0 0 0 0 ...\n $ rank             : int 7\n $ qr               :List of 5\n $ family           :List of 11\n $ linear.predictors: Named num [1:346] 8.67 8.67 16.33 -2.18 7.95 ...\n $ deviance         : num 636485\n $ aic              : num 3599\n $ null.deviance    : num 820296\n $ iter             : int 2\n $ weights          : Named num [1:346] 1 1 1 1 1 1 1 1 1 1 ...\n $ prior.weights    : Named num [1:346] 1 1 1 1 1 1 1 1 1 1 ...\n $ df.residual      : int 339\n $ df.null          : int 345\n $ y                : Named num [1:346] 2 1 1 1 1 1 80 104 55 350 ...\n $ converged        : logi TRUE\n $ boundary         : logi FALSE\n $ model            :'data.frame':\t346 obs. of  4 variables:\n $ na.action        : 'omit' Named int [1:64] 1 2 3 4 5 6 7 8 9 10 ...\n $ call             : language glm(formula = n_visits ~ gender + income + travel, data = snake_river_visits)\n $ formula          :Class 'formula'  language n_visits ~ gender + income + travel\n $ terms            :Classes 'terms', 'formula'  language n_visits ~ gender + income + travel\n $ data             :'data.frame':\t410 obs. of  4 variables:\n $ offset           : NULL\n $ control          :List of 3\n $ method           : chr \"glm.fit\"\n $ contrasts        :List of 3\n $ xlevels          :List of 3\nn_visits :  num [1:410] 0 0 0 0 0 0 0 0 0 0 ...\nobs : tibble [346 × 11] (S3: tbl_df/tbl/data.frame)\nparent : <environment: R_GlobalEnv> \npipeable_plot : function (data, formula)  \nplt_dist_vs_speed : 'data.frame':\t50 obs. of  2 variables:\n $ speed: num  4 4 7 7 8 9 10 10 10 11 ...\n $ dist : num  2 10 4 22 16 10 18 26 34 17 ...\nrsa_env : <environment: 0x5571ce3fdae8> \nrsa_lst : List of 3\n $ capitals      : chr [1:2] \"J Burg\" \"Capetown\"\n $ national_parks: chr [1:2] \"Krug\" \"Iddo\"\n $ population    : num 30000\nrun_poisson_regression : function (data, formula)  \nsnake_river_visits : 'data.frame':\t410 obs. of  4 variables:\n $ n_visits: num  0 0 0 0 0 0 0 0 0 0 ...\n $ gender  : Factor w/ 2 levels \"male\",\"female\": 1 1 1 2 1 2 2 2 1 1 ...\n $ income  : Factor w/ 4 levels \"[$0,$25k]\",\"($25k,$55k]\",..: 4 2 4 2 4 2 4 4 4 4 ...\n $ travel  : Factor w/ 3 levels \"[0h,0.25h]\",\"(0.25h,4h]\",..: NA NA NA NA NA NA NA NA NA NA ...\nstd_and_poor500 : 'data.frame':\t505 obs. of  5 variables:\n $ symbol  : chr  \"MMM\" \"ABT\" \"ABBV\" \"ABMD\" ...\n $ company : chr  \"3M Company\" \"Abbott Laboratories\" \"AbbVie Inc.\" \"ABIOMED Inc\" ...\n $ sector  : chr  \"Industrials\" \"Health Care\" \"Health Care\" \"Health Care\" ...\n $ industry: chr  \"Industrial Conglomerates\" \"Health Care Equipment\" \"Pharmaceuticals\" \"Health Care Equipment\" ...\n $ pe_ratio: num  18.3 57.7 22.4 45.6 27 ...\ntoss_coin : function (n_flips, p_head)  \n```\n:::\n\n```{.r .cell-code}\nls.str(rsa_env)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncapitals :  chr [1:2] \"J Burg\" \"Capetown\"\nnational_parks :  chr [1:2] \"Krug\" \"Iddo\"\npopulation :  num 30000\n```\n:::\n\n```{.r .cell-code}\n# Does population exist in rsa_env?\nexists(\"population\", envir = rsa_env)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n# Does population exist in rsa_env, ignoring inheritance?\nexists(\"population\", envir = rsa_env, inherits = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\n## Converting areas to metric 1\n\nIn this chapter, you'll be working with grain yield data from the United States Department of Agriculture, National Agricultural Statistics Service. Unfortunately, they report all areas in acres. So, the first thing you need to do is write some utility functions to convert areas in acres to areas in hectares.\n\nTo solve this exercise, you need to know the following:\n\nThere are 4840 square yards in an acre. There are 36 inches in a yard and one inch is 0.0254 meters. There are 10000 square meters in a hectare.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Write a function to convert acres to sq. yards\nacres_to_sq_yards <- function(acres) {\n  acres * 4840\n}\n\n# Write a function to convert yards to meters\nyards_to_meters <- function(yards){\n    yards * 36*0.0254\n}\n\n# Write a function to convert sq. meters to hectares\n# Write a function to convert yards to meters\nsq_meters_to_hectares <- function(sq_meters){\n    sq_meters/10000\n}\n```\n:::\n\n\n## Converting areas to metric 2\n\nYou're almost there with creating a function to convert acres to hectares. You need another utility function to deal with getting from square yards to square meters. Then, you can bring everything together to write the overall acres-to-hectares conversion function. Finally, in the next exercise you'll be calculating area conversions in the denominator of a ratio, so you'll need a harmonic acre-to-hectare conversion function.\n\nFree hints: magrittr's raise_to_power() will be useful here. The last step is similar to Chapter 2's Harmonic Mean.\n\nThe three utility functions from the last exercise (acres_to_sq_yards(), yards_to_meters(), and sq_meters_to_hectares()) are available, as is your get_reciprocal() from Chapter 2. magrittr is loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Write a function to convert sq. yards to sq. meters\nsq_yards_to_sq_meters <- function(sq_yards) {\n  sq_yards %>%\n    # Take the square root\n    sqrt() %>%\n    # Convert yards to meters\n    yards_to_meters() %>%\n    # Square it\n    raise_to_power(2)\n}\n\n# Load the function from the previous step\n#load_step2()\n\n# Write a function to convert acres to hectares\nacres_to_hectares <- function(acres) {\n  acres %>%\n    # Convert acres to sq yards\n    acres_to_sq_yards() %>%\n    # Convert sq yards to sq meters\n    sq_yards_to_sq_meters() %>%\n    # Convert sq meters to hectares\n    sq_meters_to_hectares()\n}\n\n# Define a harmonic acres to hectares function\nharmonic_acres_to_hectares <- function(acres) {\n  acres %>% \n    # Get the reciprocal\n    get_reciprocal() %>%\n    # Convert acres to hectares\n    acres_to_hectares %>% \n    # Get the reciprocal again\n    get_reciprocal()\n}\n```\n:::\n\n\n## Converting yields to metric\n\nThe yields in the NASS corn data are also given in US units, namely bushels per acre. You'll need to write some more utility functions to convert this unit to the metric unit of kg per hectare.\n\nBushels historically meant a volume of 8 gallons, but in the context of grain, they are now defined as masses. This mass differs for each grain! To solve this exercise, you need to know these facts.\n\nOne pound (lb) is 0.45359237 kilograms (kg). One bushel is 48 lbs of barley, 56 lbs of corn, or 60 lbs of wheat. magrittr is loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\n# Write a function to convert lb to kg\nlbs_to_kgs <- function(lbs){\n    lbs * 0.45359237\n}\n\n# Write a function to convert bushels to lbs\nbushels_to_lbs <- function(bushels, crop) {\n  # Define a lookup table of scale factors\n  c(barley = 48, corn = 56, wheat = 60) %>%\n    # Extract the value for the crop\n    magrittr::extract(crop) %>%\n    # Multiply by the no. of bushels\n    multiply_by(bushels)\n}\n\n\n# Write a function to convert bushels to kg\nbushels_to_kgs <- function(bushels, crop) {\n  bushels %>%\n    # Convert bushels to lbs for this crop\n    bushels_to_lbs(crop) %>%\n    # Convert lbs to kgs\n    lbs_to_kgs()\n}\n\n\n\n# Write a function to convert bushels/acre to kg/ha\nbushels_per_acre_to_kgs_per_hectare <- function(bushels_per_acre, crop = c(\"barley\", \"corn\", \"wheat\")) {\n  # Match the crop argument\n  crop <- match.arg(crop)\n  bushels_per_acre %>%\n    # Convert bushels to kgs for this crop\n    bushels_to_kgs(crop) %>%\n    # Convert harmonic acres to ha\n    harmonic_acres_to_hectares()\n}\n```\n:::\n\n\n## Applying the unit conversion\n\nNow that you've written some functions, it's time to apply them! The NASS corn dataset is available, and you can fortify it (jargon for \"adding new columns\") with metrics areas and yields.\n\nThis fortification process can also be turned in to a function, so you'll define a function for this, and test it on the NASS wheat dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorn <- readRDS(\"nass.corn.rds\")\nwheat <- readRDS(\"nass.wheat.rds\")\nglimpse(corn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6,381\nColumns: 4\n$ year                   <int> 1866, 1866, 1866, 1866, 1866, 1866, 1866, 1866,…\n$ state                  <chr> \"Alabama\", \"Arkansas\", \"California\", \"Connectic…\n$ farmed_area_acres      <dbl> 1050000, 280000, 42000, 57000, 200000, 125000, …\n$ yield_bushels_per_acre <dbl> 9.0, 18.0, 28.0, 34.0, 23.0, 9.0, 6.0, 29.0, 36…\n```\n:::\n\n```{.r .cell-code}\ncorn %>%\n  # Add some columns\n  mutate(\n    # Convert farmed area from acres to ha\n    farmed_area_ha = acres_to_hectares(farmed_area_acres),\n    # Convert yield from bushels/acre to kg/ha\n    yield_kg_per_ha = bushels_per_acre_to_kgs_per_hectare(\n      yield_bushels_per_acre,\n      crop = \"corn\"\n    )\n  ) %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  year       state farmed_area_acres yield_bushels_per_acre farmed_area_ha\n1 1866     Alabama           1050000                      9      424919.92\n2 1866    Arkansas            280000                     18      113311.98\n3 1866  California             42000                     28       16996.80\n4 1866 Connecticut             57000                     34       23067.08\n5 1866    Delaware            200000                     23       80937.13\n6 1866     Florida            125000                      9       50585.71\n  yield_kg_per_ha\n1         564.909\n2        1129.818\n3        1757.495\n4        2134.101\n5        1443.656\n6         564.909\n```\n:::\n\n```{.r .cell-code}\n# Wrap this code into a function\nfortify_with_metric_units <- function(data, crop){\n\n\n  data %>%\n    mutate(\n      farmed_area_ha = acres_to_hectares(farmed_area_acres),\n      yield_kg_per_ha = bushels_per_acre_to_kgs_per_hectare(\n        yield_bushels_per_acre, \n        crop = crop\n      )\n    )\n}\n\n# Try it on the wheat dataset\nwheat <- fortify_with_metric_units(wheat, crop = \"wheat\")\n```\n:::\n\n\n## Plotting yields over time\n\nNow that the units have been dealt with, it's time to explore the datasets. An obvious question to ask about each crop is, \"how do the yields change over time in each US state?\" Let's draw a line plot to find out! ggplot2 is loaded, and corn and wheat datasets are available with metric units.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrap this plotting code into a function\nplot_yield_vs_year <- function(data){\n  ggplot(data, aes(year, yield_kg_per_ha)) +\n    geom_line(aes(group = state)) +\n    geom_smooth()\n}\n\n# Test it on the wheat dataset\nplot_yield_vs_year(wheat)\n```\n\n::: {.cell-output-display}\n![](functions_R_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n## A nation divided\n\nThe USA has a varied climate, so we might expect yields to differ between states. Rather than trying to reason about 50 states separately, we can use the USA Census Regions to get 9 groups.\n\nThe \"Corn Belt\", where most US corn is grown is in the \"West North Central\" and \"East North Central\" regions. The \"Wheat Belt\" is in the \"West South Central\" region.\n\ndplyr is loaded, the corn and wheat datasets are available, as is usa_census_regions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Inner join the corn dataset to usa_census_regions by state\nlibrary(data.table)\nusa_census_regions <- read_csv(\"usa_census_regions.csv\")\nsetnames(usa_census_regions, c(\"State\", \"Region\"), c(\"state\", \"census_region\"))\nView(usa_census_regions)\n# corn %>%\n#   inner_join(usa_census_regions, by= \"state\")\n# Wrap this code into a function\nfortify_with_census_region <- function(data){\n  data %>%\n    inner_join(usa_census_regions, by = \"state\")\n}\n\n# Try it on the wheat dataset\nwheat <- fortify_with_census_region(wheat)\n```\n:::\n\n\n## Plotting yields over time by region\n\nSo far, you have a function to plot yields over time for each crop, and you've added a census_region column to the crop datasets. Now you are ready to look at how the yields change over time in each region of the USA.\n\nggplot2 is loaded. corn and wheat have been fortified with census regions. plot_yield_vs_year() is available.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrap this code into a function\nplot_yield_vs_year_by_region <- function(data) {\n\n  plot_yield_vs_year(data) +\n    facet_wrap(vars(census_region))\n}\n\n# Try it on the wheat dataset\n\nplot_yield_vs_year_by_region(wheat)\n```\n\n::: {.cell-output-display}\n![](functions_R_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n## Running a model\n\nThe smooth trend line you saw in the plots of yield over time use a generalized additive model (GAM) to determine where the line should lie. This sort of model is ideal for fitting nonlinear curves. So we can make predictions about future yields, let's explicitly run the model. The syntax for running this GAM takes the following form.\n\ngam(response \\~ s(explanatory_var1) + explanatory_var2, data = dataset) Here, s() means \"make the variable smooth\", where smooth very roughly means nonlinear.\n\nmgcv and dplyr are loaded; the corn and wheat datasets are available.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrap the model code into a function\nlibrary(mgcv)\nrun_gam_yield_vs_year_by_region <- function(data){\n\n\n  gam(yield_kg_per_ha ~ s(year) + census_region, data = data)\n\n}\n\n# Try it on the wheat dataset\nwheat_model <- run_gam_yield_vs_year_by_region(wheat)\nwheat_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nyield_kg_per_ha ~ s(year) + census_region\n\nEstimated degrees of freedom:\n6.93  total = 10.93 \n\nGCV score: 341585.5     \n```\n:::\n:::\n\n\n## Making yield predictions\n\nThe fun part of modeling is using the models to make predictions. You can do this using a call to predict(), in the following form.\n\npredict(model, cases_to_predict, type = \"response\") mgcv and dplyr are loaded; GAMs of the corn and wheat datasets are available as corn_model and wheat_model. A character vector of census regions is stored as census_regions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_regions <- wheat$census_region %>% unique()\n# Wrap this prediction code into a function\npredict_yields <- function(model, year){\n\n  predict_this <- data.table(\n    year = year,\n    census_region = census_regions\n  ) \n  pred_yield_kg_per_ha <- predict(model, predict_this, type = \"response\")\n  predict_this %>%\n    mutate(pred_yield_kg_per_ha = pred_yield_kg_per_ha)\n}\n\n# Try it on the wheat dataset\npredict_yields(wheat_model, year = 2050)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year census_region pred_yield_kg_per_ha\n1: 2050         South       <multi-column>\n2: 2050          West       <multi-column>\n3: 2050     Northeast       <multi-column>\n4: 2050       Midwest       <multi-column>\n```\n:::\n:::\n\n\n## Do it all over again\n\nHopefully, by now, you've realized that the real benefit to writing functions is that you can reuse your code easily. Now you are going to rerun the whole analysis from this chapter on a new crop, barley. Since all the infrastructure is in place, that's less effort than it sounds!\n\nBarley prefers a cooler climate compared to corn and wheat and is commonly grown in the US mountain states of Idaho and Montana.\n\ndplyr and ggplot2, and mgcv are loaded; fortify_with_metric_units(), fortify_with_census_region(), plot_yield_vs_year_by_region(), run_gam_yield_vs_year_by_region(), and predict_yields() are available.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfortified_barley <- barley %>% \n  # Fortify with metric units\n  fortify_with_metric_units() %>%\n  # Fortify with census regions\n  fortify_with_census_region()\n\n# See the result\nglimpse(fortified_barley)\n# From previous step\nfortified_barley <- barley %>% \n  fortify_with_metric_units() %>%\n  fortify_with_census_region()\n\nfortified_barley %>% \n  # Run a GAM of yield vs. year by region\n  run_gam_yield_vs_year_by_region %>% \n  # Make predictions of yields in 2050\n  predict_yields(year = 2050)\n```\n:::\n",
    "supporting": [
      "functions_R_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}