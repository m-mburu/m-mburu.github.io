{
  "hash": "d6701fb6ae0eb561a315d79628d30927",
  "result": {
    "markdown": "---\ntitle: \"Association analysis\"\nauthor: \"Mburu\"\ndate: \"November 27, 2018\"\noutput:\n     html_document\ncategories: [news, code, analysis]\n---\n\n\n\n\n# Association Analysis\n\nMaybe you have heard of a grocery store that carried out analysis and found out that men who buy diapers between 5pm to 7pm were more likely to buy beer. The grocery store then moved the beer isle closer to the diaper isle and beer sales increased by 35%. This is called association analysis which was motivated by retail store data.\n\nIn this blog I will explore the basics of association analysis. The goal is to find out:\n\n-   Items frequently bought together in association analysis this is called support. Let say you have ten transactions and in those ten 3 transactions have maize floor, rice and bread the the support for maize floor, rice and bread is 3/10 = 0.3. This is just marginal probability. In other terms the percentage of transactions these items were bought together.\n\n-   In this example the support is written as Support({bread, maize floor} --\\> {rice} ). In general this is written as Support of item one and item 2 is Support({item1} --\\> {item 2}). Item 1 and item 2 may contain one or more items.\n\n-   We also want to find out if someone bought a set of items what other set of item(s) were they likely to buy. In association analysis this is called confidence. In our above example let say that you find the proportion of transactions that contained maize floor and bread are 0.4. Then the confidence is the proportion of those transactions with maize floor, bread and rice/proportion of transactions that contained maize floor and bread. Then the confidence is 0.3/0.4 which is 0.75. In other word 75% of those who bought maize floor and bread also bought rice.\n\n    -   Confidence in this example is denoted as Confidence({bread, maize floor} --\\> {rice} ) and in general this is Confidence({item 1} --\\> {item 2} ).\n\n-   The lift refers to how the chances of rice being purchased increased given that maize floor and bread are purchased. So the lift of rice is confidence of rice/support(rice). Support of rice is the number of transactions that contain rice.\n\n    -   Lift({Item 1} -\\> {Item 2 }) = (Confidence(Item1 -\\> Item2)) / (Support(Item2))\n\nTo make sense of all these I'm going to use a bakery to find association rules between items bought manually and then towards the end I will use r package arules which uses apriori algorithm to find association between items bought. The data set is available on kaggle as BreadBasket_DMS. We start by first having a glimpse of this data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(data.table)\nlibrary(DT)\n\ndat <- setDT(read.csv( \"BreadBasket_DMS.csv\" ))\n\ndat <- dat[Item != \"NONE\"]\nhead(dat[sample(1:nrow(dat), 10)]) %>% datatable()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-f1fe63e4983c163a8f21\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f1fe63e4983c163a8f21\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"2017-01-26\",\"2017-02-27\",\"2017-01-27\",\"2016-12-17\",\"2017-02-01\",\"2016-12-21\"],[\"12:13:16\",\"14:26:27\",\"11:52:12\",\"15:16:25\",\"16:00:36\",\"14:43:08\"],[5358,7307,5415,3367,5770,3620],[\"Coffee\",\"Coffee\",\"Sandwich\",\"Hot chocolate\",\"Coffee\",\"Coffee\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Date<\\/th>\\n      <th>Time<\\/th>\\n      <th>Transaction<\\/th>\\n      <th>Item<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":3},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n## Data Cleaning and Exploratory Data Analysis\n\nFirst step is to transform the data set into wide format. Column headers will be items sold in the bakery and the rows will be populated with 1 and 0 indicating whether that item was bought for that transaction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 <- dcast(Date+Time+Transaction~Item, data = dat, fun.aggregate = length)\n#dat2[, NONE := NULL]\n\nsample_cols <- sample(4:ncol(dat2), 5)\n\nitem_names <- names(dat2)[4:97]\n\ndat2[, (item_names) := lapply(.SD, function(x) ifelse(x==0, 0, 1)), .SDcols = item_names]\n\nhead(dat2[, c(1:3, sample_cols), with = F]) %>% datatable()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-9f0339a712bfd0c9cb47\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-9f0339a712bfd0c9cb47\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"2016-10-30\",\"2016-10-30\",\"2016-10-30\",\"2016-10-30\",\"2016-10-30\",\"2016-10-30\"],[\"09:58:11\",\"10:05:34\",\"10:07:57\",\"10:08:41\",\"10:13:03\",\"10:16:55\"],[1,2,3,4,5,6],[0,0,0,0,0,0],[0,0,0,1,0,1],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Date<\\/th>\\n      <th>Time<\\/th>\\n      <th>Transaction<\\/th>\\n      <th>Coffee granules <\\/th>\\n      <th>Muffin<\\/th>\\n      <th>Christmas common<\\/th>\\n      <th>Mortimer<\\/th>\\n      <th>Cake<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[3,4,5,6,7,8]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n## How many items each customer buy?\n\nOn average a transaction has 2 items. The median is also 2, this shows that atleast 50% of the transactions contained 2 or more items and atleast 25% of the transactions have 1 item.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnumber_items <- rowSums(dat2[, 4:97, with =F])\n\ndat2[, number_items := number_items]\n\nhist(number_items, col = \"black\", main = \"Number of items bought\")\n```\n\n::: {.cell-output-display}\n![](association_analysis_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsumStats <- dat2 %>%\n    summarise(Average = round(mean(number_items), 2), Stdev = round(sd(number_items), 2),\n              Median= median(number_items),\n              Minimum = min(number_items), Maximum = max(number_items),\n              First_qurtile = quantile(number_items,0.25,  na.rm = T),\n              Third_qurtile=quantile(number_items,0.75,  na.rm = T))\n\ndatatable(sumStats)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-2fd30b06f7fdc9f4ca09\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-2fd30b06f7fdc9f4ca09\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\"],[2],[1.13],[2],[1],[10],[1],[3]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Average<\\/th>\\n      <th>Stdev<\\/th>\\n      <th>Median<\\/th>\\n      <th>Minimum<\\/th>\\n      <th>Maximum<\\/th>\\n      <th>First_qurtile<\\/th>\\n      <th>Third_qurtile<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5,6,7]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n## Top 10 bought items\n\nTable below shows top ten most bought items and about 47.84% of the transactions contained coffee. Coffee was the most popular item in this bakery followed by bread.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_transacts_item_in <- colSums(dat2[, item_names, with = F])\n\ndata.frame(item = names(n_transacts_item_in),\n           number =n_transacts_item_in) %>%\n    mutate(Percentage = round(number/nrow(dat2)*100, 2)) %>%\n    arrange(desc(number)) %>% head(10) %>% datatable()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-91aaf8b36894875b3369\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-91aaf8b36894875b3369\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"Coffee\",\"Bread\",\"Tea\",\"Cake\",\"Pastry\",\"Sandwich\",\"Medialuna\",\"Hot chocolate\",\"Cookies\",\"Brownie\"],[\"Coffee\",\"Bread\",\"Tea\",\"Cake\",\"Pastry\",\"Sandwich\",\"Medialuna\",\"Hot chocolate\",\"Cookies\",\"Brownie\"],[4528,3097,1350,983,815,680,585,552,515,379],[47.84,32.72,14.26,10.39,8.61,7.18,6.18,5.83,5.44,4]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>item<\\/th>\\n      <th>number<\\/th>\\n      <th>Percentage<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nSince we have transformed the data in the wide format and every transaction is in it's row we can visualize how the baskets look like. This is done by extracting the column names for the transactions where the value is 1. For each transaction, 1 represent that item being in that transaction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nitems_bought <- apply(dat2[, 4:97, with =F], 1, paste, collapse = \"\", sep = \"\")\n\nlist_items <- vector(mode = \"list\", length = length(items_bought))\nfor (i in 1:length(items_bought)) {\n    index <- unlist(gregexpr(\"1\", items_bought[i]))\n    items_transaction_i <- item_names[index]\n    items_transaction_i <- paste(items_transaction_i, sep = \" \", collapse = \" , \")\n    list_items[[i]] <- items_transaction_i\n}\n\nhead(unlist(list_items))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Bread\"                         \"Scandinavian\"                 \n[3] \"Cookies , Hot chocolate , Jam\" \"Muffin\"                       \n[5] \"Bread , Coffee , Pastry\"       \"Medialuna , Muffin , Pastry\"  \n```\n:::\n:::\n\n\nData frame below shows how the baskets look like. Only 10 randomly selected rows are displayed. Items_bought column shows the baskets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2[, items_bought := unlist(list_items) ]\n\nhead(dat2[sample(1:nrow(dat2), 10),\n          .(Transaction, number_items,items_bought)]) %>%\n  datatable()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-2f536adca9736c64ce14\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-2f536adca9736c64ce14\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[4472,8442,696,6779,7288,1378],[1,1,1,3,2,2],[\"Muffin\",\"Sandwich\",\"Tartine\",\"Bread , Brownie , Pastry\",\"Bread , Coffee\",\"Bread , Coffee\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Transaction<\\/th>\\n      <th>number_items<\\/th>\\n      <th>items_bought<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nA small example which I will work out manually to see what is the support for ({coffee, bread} --\\> {jam}). Generally I want to see how many transactions contained these 3 items. 0.12% of the transactions contained {bread, coffee, jam}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_item_set <- Hmisc::Cs(Coffee , Jam , Bread)\n\nidx_sample <- grep( \"Transactio|^Coffee$|^Jam$|^Bread$\", names(dat2))\n\n\n\nitem_set_dat <- dat2[, idx_sample, with = F] \n\n#some transaction bought more thanone of \nitem_set_dat[, (my_item_set) := lapply(.SD, function(x) ifelse(x==0, 0, 1)), .SDcols = my_item_set]\n\nitem_set_dat[, total_items := rowSums(item_set_dat[, 2:4, with = F]) ]\n\nsupport_coffee_bread_jam <- table(item_set_dat$total_items)[\"3\"]/9531 \n\nsupport_coffee_bread_jam\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          3 \n0.001154129 \n```\n:::\n:::\n\n\nTo calculate confidence({bread, coffee} --\\> {jam}) we should also calculate the support of ({bread, coffee}) which is the prorpotion of bread and coffee appearing together in the transactions which is about 8.9% of the transactions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nitem_set_dat[, coffee_bread := rowSums(item_set_dat[, c(\"Bread\", \"Coffee\"), with = F]) ]\n\nhead(item_set_dat, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Transaction Bread Coffee Jam total_items coffee_bread\n1:           1     1      0   0           1            1\n2:           2     0      0   0           0            0\n```\n:::\n\n```{.r .cell-code}\nsupport_coffee_bread <- table(item_set_dat$coffee_bread)[\"2\"]/9531 \n\nsupport_coffee_bread\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         2 \n0.08939251 \n```\n:::\n:::\n\n\n1.3% of the people who bought bread and coffee also bought jam. This is the confidence of({bread, coffee} --\\> {jam}) For statisticians this can be translated as conditional probability. In conditional probability notations P(Jam/bread, coffee) which is probability you will buy jam given that you have already bought bread and coffee. In association analysis we have {bread, coffee} \\>\\>{jam} bread and coffee implies jam. So the confidence measures the strength/probability of this implication.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfidence <- support_coffee_bread_jam/support_coffee_bread \n\nconfidence * 100\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      3 \n1.29108 \n```\n:::\n:::\n\n\nUsing package arules we find the 10 rules with the highest confidence in descending order. Confidence({Toast} --\\>{Coffee}) had the highest confidence of 0.70440252. About 70.44% of the transactions that contained toast also contained coffee.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arules)\n\ntransactions <- as(split(dat$Item, dat$Transaction), \"transactions\")\n\nassoc_rules <- apriori(transactions,\n                 parameter = list(supp = 0.02, conf = 0.04, target = \"rules\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n       0.04    0.1    1 none FALSE            TRUE       5    0.02      1\n maxlen target  ext\n     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 189 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[94 item(s), 9465 transaction(s)] done [0.00s].\nsorting and recoding items ... [19 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 done [0.00s].\nwriting ... [38 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n```\n:::\n\n```{.r .cell-code}\nassoc_rules <- sort(assoc_rules, by='confidence', decreasing = TRUE)\n\n\ninspect(assoc_rules[1:30]) #%>% broom::tidy() %>% kable\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     lhs                rhs         support    confidence coverage   lift     \n[1]  {Toast}         => {Coffee}    0.02366614 0.70440252 0.03359746 1.4724315\n[2]  {Medialuna}     => {Coffee}    0.03518225 0.56923077 0.06180666 1.1898784\n[3]  {Pastry}        => {Coffee}    0.04754358 0.55214724 0.08610671 1.1541682\n[4]  {Juice}         => {Coffee}    0.02060222 0.53424658 0.03856313 1.1167500\n[5]  {Sandwich}      => {Coffee}    0.03824617 0.53235294 0.07184363 1.1127916\n[6]  {Cake}          => {Coffee}    0.05472795 0.52695829 0.10385631 1.1015151\n[7]  {Cookies}       => {Coffee}    0.02820919 0.51844660 0.05441099 1.0837229\n[8]  {Hot chocolate} => {Coffee}    0.02958267 0.50724638 0.05832013 1.0603107\n[9]  {}              => {Coffee}    0.47839408 0.47839408 1.00000000 1.0000000\n[10] {Tea}           => {Coffee}    0.04986793 0.34962963 0.14263074 0.7308402\n[11] {Pastry}        => {Bread}     0.02916006 0.33865031 0.08610671 1.0349774\n[12] {}              => {Bread}     0.32720549 0.32720549 1.00000000 1.0000000\n[13] {Bread}         => {Coffee}    0.09001585 0.27510494 0.32720549 0.5750592\n[14] {Cake}          => {Tea}       0.02377179 0.22889115 0.10385631 1.6047813\n[15] {Cake}          => {Bread}     0.02334918 0.22482197 0.10385631 0.6870972\n[16] {Tea}           => {Bread}     0.02810354 0.19703704 0.14263074 0.6021813\n[17] {Coffee}        => {Bread}     0.09001585 0.18816254 0.47839408 0.5750592\n[18] {Tea}           => {Cake}      0.02377179 0.16666667 0.14263074 1.6047813\n[19] {}              => {Tea}       0.14263074 0.14263074 1.00000000 1.0000000\n[20] {Coffee}        => {Cake}      0.05472795 0.11439929 0.47839408 1.1015151\n[21] {Coffee}        => {Tea}       0.04986793 0.10424028 0.47839408 0.7308402\n[22] {}              => {Cake}      0.10385631 0.10385631 1.00000000 1.0000000\n[23] {Coffee}        => {Pastry}    0.04754358 0.09938163 0.47839408 1.1541682\n[24] {Bread}         => {Pastry}    0.02916006 0.08911850 0.32720549 1.0349774\n[25] {}              => {Pastry}    0.08610671 0.08610671 1.00000000 1.0000000\n[26] {Bread}         => {Tea}       0.02810354 0.08588957 0.32720549 0.6021813\n[27] {Coffee}        => {Sandwich}  0.03824617 0.07994700 0.47839408 1.1127916\n[28] {Coffee}        => {Medialuna} 0.03518225 0.07354240 0.47839408 1.1898784\n[29] {}              => {Sandwich}  0.07184363 0.07184363 1.00000000 1.0000000\n[30] {Bread}         => {Cake}      0.02334918 0.07135938 0.32720549 0.6870972\n     count\n[1]   224 \n[2]   333 \n[3]   450 \n[4]   195 \n[5]   362 \n[6]   518 \n[7]   267 \n[8]   280 \n[9]  4528 \n[10]  472 \n[11]  276 \n[12] 3097 \n[13]  852 \n[14]  225 \n[15]  221 \n[16]  266 \n[17]  852 \n[18]  225 \n[19] 1350 \n[20]  518 \n[21]  472 \n[22]  983 \n[23]  450 \n[24]  276 \n[25]  815 \n[26]  266 \n[27]  362 \n[28]  333 \n[29]  680 \n[30]  221 \n```\n:::\n:::\n\n\nI hope with this small example you can now understand how association analysis works.\n",
    "supporting": [
      "association_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.6.1/htmlwidgets.js\"></script>\n<link href=\"../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/datatables-binding-0.27/datatables.js\"></script>\n<script src=\"../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../../site_libs/dt-core-1.12.1/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/dt-core-1.12.1/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/dt-core-1.12.1/js/jquery.dataTables.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}