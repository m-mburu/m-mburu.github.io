---
title: "Loan Prediction Zindi"
author: "mburu"
date: "April 18, 2020"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: no
    theme: united
    highlight: pygments
  html_notebook:
    toc: yes
    toc_depth: '3'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE)
```

# Introduction

## Packages used

```{r}
library(tidyverse)
library(data.table)
library(caret)
library(ggthemes)
library(lubridate)
library(DT)
```

# Description 

## Reading data

```{r}

trainperf <- fread("trainperf.csv")
traindemographics <-fread("traindemographics.csv")
testperf <-fread("testperf.csv")
testdemographics <-fread("testdemographics.csv")
SampleSubmission <- fread("SampleSubmission.csv")
```

## Combine test set and train set

- makes it easier for cleaning purposes

```{r}
train_data <- merge(traindemographics, 
                    trainperf, all.y = T,
                    by = "customerid")

test_data <- merge(testdemographics, 
                   testperf, all.y = T, 
                   by = "customerid")s

loan_data <- rbind(train_data[, set := "train"],
                   test_data[, set := "test"], fill = T)

loan_data %>% head() %>%
  datatable(options = list(scrollX= TRUE))
```

# Feature engineering

### Dates

- Create new variables from dates eg age, loan year, loan day etc

```{r}
dates <- c("birthdate" ,"approveddate", "creationdate" )
loan_data[, (dates) := lapply(.SD, as.Date), .SDcols = dates]
loan_data[, age := (as.numeric(approveddate - birthdate))/365]
loan_data[, aprove_month := month(approveddate)]
loan_data[, approve_day := wday(approveddate)]
loan_data[, approve_year := year(approveddate)]
```

## Bad loans distribution

```{r}

loan_data[!is.na(good_bad_flag), .N, by = .(good_bad_flag)] %>%
    .[, perc := round(N/sum(N) * 100, 2)] %>%
    
     ggplot(aes(good_bad_flag, perc, fill =good_bad_flag)) +
     geom_bar(stat = "identity") +
     geom_text(aes(good_bad_flag, perc, label = paste(perc, "%"),
                   vjust = .05, hjust = .5),
               size = 4)+
     theme_hc()+
    labs(title = "Percentage of bad loans")+
     scale_fill_colorblind(name = "")+
    theme(legend.position = "none")



```

# Some cleaning

## Clean string variables

- convert empty chars to NA



```{r}
chars <- c("bank_account_type", "bank_name_clients", 
           "bank_branch_clients", "employment_status_clients",
           "level_of_education_clients")

loan_data[, (chars) := lapply(.SD, function(x) ifelse(x == "" | x == " ", NA, x)), .SDcols = chars]
```


## Missing values distribution

```{r}

naVals <- colSums(is.na(loan_data))/nrow(loan_data) * 100 

withNa <- naVals[naVals>0]
nms_na <- names(withNa)
missing_perc <- data.table(variables = nms_na, perc = withNa) 


```


## Missing values distribution plot

```{r}
ggplot(missing_perc, aes( reorder(variables, perc), perc))+
    geom_bar(stat = "identity") +
    theme_fivethirtyeight()+
    coord_flip()
```

## KNN imputation

```{r}
loan_data[, loannumber := as.numeric(loannumber)]
missing_var_del <- missing_perc[perc>50, variables]
## KNN imputation
library(VIM)
loan_data[, (dates):= NULL]
loan_data[, referredby:= NULL]
loan_data <- kNN(loan_data,useImputedDist = FALSE, k =10)

setDT(loan_data)
nms_all <- names(loan_data)
nms_imp <- nms_all[grepl("_imp$", nms_all)]


loan_data[, (nms_imp) := lapply(.SD, 
                            function(x) ifelse(x == FALSE, 0, 1)),
      .SDcols = nms_imp]

col_sum_imp <- loan_data[, colSums(.SD), .SDcols = nms_imp]
col_sum_imp <- names(col_sum_imp[col_sum_imp == 0])
#var_importants <- fread("var_importanta.csv")
loan_data[, (col_sum_imp) := NULL]

loan_data %>% head() %>%
  datatable(options = list(scrollX= TRUE))
```

## More cleaning

- eg standardizing 

```{r}


loan_data[, good_bad_flag := factor(good_bad_flag, levels = c("Bad", "Good"))]

nms_del1 <- c("set_imp", " good_bad_flag_imp", 
              "approve_year","aprove_month", 
              "year","systemloanid" )

loan_data[, (nms_del1) := NULL]

class_nms <- sapply(loan_data, class)
nums <- class_nms[class_nms == "numeric"] %>% names()
nums <- nums[!grepl("_imp|good_bad_flag", nums)]

zero_one <- function(x){
    
    myvar <- (x - min(x))/(max(x) - min(x))
    
    myvar
}


loan_data[, (nums) := lapply(.SD, zero_one), .SDcols = nums]


train_data <- loan_data[set == "train"]
train_data[, set:= NULL]
test_data <- loan_data[set == "test"]
test_data[, set:= NULL]
```

## Imbalanced Datasets

- make the proportion  of good loans to be the same as that of bad loans 

```{r}

train_bad <- train_data[good_bad_flag == "Bad"]
train_good <- train_data[good_bad_flag == "Good"]
n_row = nrow(train_good)
n_row_dead = nrow(train_bad)

set.seed(200)
not_sample <- sample(1:n_row, n_row_dead)
train_good <- train_good[not_sample]
train_sampled <- rbind(train_bad, train_good)

```


# Training Data

## Tuning parameters and validation sets

```{r}
## Model Cross validation

set.seed(100)
cv_fold <- createFolds(train_sampled$good_bad_flag, k = 10)

train_ctrl <- trainControl(method = "cv",
                        number = 10,
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE,
                        allowParallel=T,
                        index = cv_fold,
                        verboseIter = FALSE,
                        savePredictions = TRUE,
                        search = "grid")


xgb_grid <- expand.grid(nrounds = c(50,100),
                        eta = 0.4,
                        max_depth = c(2,3),
                        gamma = c(0, .01),
                        colsample_bytree = c(0.6, .8, 1),
                        min_child_weight = 1,
                        subsample =  c(.5, .8, 1))

 
ranger_grid <- expand.grid(splitrule = c("extratrees", "gini"),
                        mtry = c(10, 20, (ncol(train_data) - 2) ),
                        min.node.size = c(1, 5))

svm_grid <- expand.grid(C = c( 1, 3, 5, 20),
                        sigma = seq(0.001, 0.524 , length.out = 7))



```


## Model Fitting



```{r}
library(caret)
library(caretEnsemble)
library(tictoc)
#tuneGrid= xgb_grid
tic()

model_list <- caretList(
   good_bad_flag~.,
    data=train_sampled[, .SD, .SDcols = !"customerid"],
    metric = "ROC",
    trControl=train_ctrl,
    tuneList = list(caretModelSpec(method="xgbTree",tuneGrid= xgb_grid ),
                    caretModelSpec(method = "svmRadial", tuneGrid = svm_grid),
                    caretModelSpec(method="ranger", tuneGrid= ranger_grid)


                   )
)

toc()
```

## Model Output

```{r}
model_list
```

# Model Perfomance

## ROC CI


```{r}

resamples_models <- resamples(model_list)

dotplot(resamples_models, metric = "ROC")

```




## Model Statistics


```{r}
nms_models <- names(model_list)
resamples_stat_list <- list()
for (j in 1:length(nms_models)) {
  model1 = model_list[[j]]
  resample_stata <- thresholder(model1, 
                              threshold = seq(.0, 1, by = 0.01), 
                              final = TRUE, 
                              statistics = "all") %>% setDT()
  p= ggplot(resample_stata , aes(x = prob_threshold, y = F1, col = "F1")) + 
  geom_point() + 
  geom_point(aes(y = Sensitivity, col = "Sensitivity"))+
  scale_x_continuous(breaks = seq(0, 1, by =.1))+
    ggtitle(nms_models[j])
  print(p)
  resample_stata[, model:= nms_models[j]]
  resamples_stat_list[[j]] = resample_stata
}



  
```

## ROC CURVE


```{r}
resamples_combined <- rbindlist(resamples_stat_list, fill = TRUE)
library(plotly)
ggplotly(ggplot(resamples_combined  , aes(x = 1-Specificity, y = Recall, color = model)) + 
  geom_line(size = 1) + 
  #geom_point(aes(y = Sensitivity, col = "Sensitivity"))+
  scale_x_continuous(breaks = seq(0, 1, by =.1)) +
  ggtitle(paste0("ROC for models"))+
  scale_color_viridis_d())



```


## Precision Recall Curve


```{r}


ggplotly(ggplot(resamples_combined ,
                aes( x = Recall, y = Precision, color = model)) + 
  geom_line(size = 1) + 
  #geom_point(aes(y = Sensitivity, col = "Sensitivity"))+
  scale_x_continuous(breaks = seq(0, 1, by =.1))+
  scale_color_viridis_d()+
  ggtitle(paste0("Precision recall curve")))


```

# Variable Importance

## IML models 

```{r}
library(iml)
X_pred <-train_sampled[, .SD, .SDcols = !c("customerid", "good_bad_flag")] %>%
  as.data.frame()

nms_models <- names(model_list)

iml_models <- list()

for (i in 1:length(nms_models)) {
  
  chain_rf_a <- model_list[[i]]
  pred <- function(chain_rf_a, train_sampled)  {
    results <- predict(chain_rf_a, newdata = train_sampled, type = "prob")
    return(results[[1L]])
  }
  
  # it does not know how to deal with char values


# get predicted values
  iml_models[[i]] <- Predictor$new(model = chain_rf_a, 
                      data =X_pred,
                      predict.function = pred,
                      y = train_sampled$good_bad_flag)


}



```


## Feature Importance plots


```{r}
plots <- list()
for (i in 1:length(nms_models)) {
  model_this = iml_models[[i]]
  impa <- FeatureImp$new(model_this, loss = "ce")
  var_importanta <-impa$results %>% data.table()

  #write.csv(var_importanta, file = "var_importanta.csv", row.names = F)
  setorder(var_importanta, -importance)
  var10a <- var_importanta[1:20]
  if(i == 2) write.csv(var10a, file = "svm_var.csv", row.names = F)
  plots[[i]] <- ggplot(var10a, aes(reorder(feature,importance), importance))+
  geom_point()+
  ggtitle(nms_models[i])+
   geom_linerange(aes(ymin=importance.05, ymax= importance.95), width=.3,
                  position=position_dodge(width = .7)) +
  coord_flip()
  
  
}

plots
```

## Shap Values calculation


```{r}
nms <- names(model_list)
ids <- which(nms == "ranger")
shap_list <- vector("list", nrow(X_pred))
model_list_shap <- list()
model_this <- iml_models[[ids]]

tic()

#shap_list[[1]] <- shap_import

for (i in 1:nrow(X_pred)) {
  shap <- Shapley$new(model_this,  x.interest = X_pred[i, ], sample.size = 30)
  shap_import <-shap$results %>% data.table()
  shap_import <- shap_import[class == "Bad"]
  shap_list[[i]] <- shap_import[,
                                customerid := train_sampled[i, customerid]]

  }
toc()
shap_values <- rbindlist(shap_list, fill = T)

write.csv(shap_values, file = "shap_values.csv", row.names = F)


```


## Shap Values plot

```{r}
library(ggforce)
shap_values <-  fread("shap_values.csv")

shap_values[, phi2 := abs(phi)]
shap_imp <- shap_values[, .(Med = median(phi2),
                            Mean = mean(phi2)), by = feature] %>%
    setorder(-Mean)
shap_imp <- shap_imp[1:20, ]

shap_values <- shap_values[feature %in%shap_imp$feature]

shap_values[, feature := factor(feature, levels = rev(shap_imp$feature) )]

ggplot(shap_values, aes(feature, phi,  color = phi.var))+
  geom_sina()+
  geom_hline(yintercept = 0) +
  scale_color_gradient(low="#2187E3", high="#F32858", 
                       breaks=c(0,1), labels=c("Low","High"))+ 
  theme_bw() + 
    theme(axis.line.y = element_blank(), 
          axis.ticks.y = element_blank(), # remove axis line
          legend.position="bottom") +
  coord_flip()

```

