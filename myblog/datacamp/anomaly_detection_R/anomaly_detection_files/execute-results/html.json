{
  "hash": "7d80bcc87e2b8ea4f0d6887fc4fa937c",
  "result": {
    "markdown": "---\ntitle: \"Anomaly Detection in R\"\nauthor: \"Mburu\"\ndate: \"2023-02-05\"\noutput:\n  html_document:\n    toc: yes\n    toc_depth: 3\n    toc_float:\n      collapsed: no\n      smooth_scroll: no\n    css: style.css\n    highlight: pygments\n---\n\n\n\n\n## Statistical outlier detection\n\n### Exploring the river nitrate data\nIn this exercise, you'll explore the river dataset which will be used throughout this chapter to illustrate the use of common anomaly detection techniques. The river data is a data.frame that contains the following three columns:\n\nindex - integers describing the order of the nitrate observations\nnitrate - monthly concentrations of dissolved nitrate found in a river\nmonth - a factor containing the month for each nitrate observation\nYou will explore the nitrate column using summary statistics and boxplots to assess whether there may be point anomalies present.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(DT)\nlibrary(outliers)\nlibrary(AnomalyDetection)\nlibrary(FNN)\nsource(\"river_data.R\")\nhead(river) %>% data_table()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-3557aee3b0f2cfb010ef\" style=\"width:100%;height:auto;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3557aee3b0f2cfb010ef\">{\"x\":{\"style\":\"bootstrap4\",\"filter\":\"none\",\"vertical\":false,\"data\":[[1.581,1.323,1.14,1.245,1.072,1.483],[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\"],[1,2,3,4,5,6]],\"container\":\"<table class=\\\"table table-bordered table-striped\\\">\\n  <thead>\\n    <tr>\\n      <th>nitrate<\\/th>\\n      <th>months<\\/th>\\n      <th>index<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"scrollX\":true,\"columnDefs\":[{\"className\":\"dt-center\",\"targets\":[1,2,3]},{\"className\":\"dt-right\",\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n\n```{.r .cell-code}\n# Summary statistics of river nitrate concentrations\nsummary(river$nitrate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.5920  0.9485  1.0680  1.0649  1.1700  1.8970 \n```\n:::\n\n```{.r .cell-code}\n# Plot the distribution of nitrate concentration\n\nboxplot(river$nitrate)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-1-2.png){width=1800}\n:::\n:::\n\n\n### Visual check of normality\nBefore using Grubbs' test, you should first check that the observations are plausibly normal. The hist() function in R returns a histogram of the observations, which will help you to form a judgement about the normal assumption. hist() is used as follows\n\nhist(data, xlab = \"My x-axis label\", breaks = 30)\n\ndata is a vector of numeric values\nbreaks the number of break points used to assign the data to bins\nxlab an optional character string for the x-axis label\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Separate the histogram into 40 bins \nhist(river$nitrate, xlab = \"Nitrate concentration\", breaks = 40)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-2-1.png){width=1800}\n:::\n:::\n\n\n\n### Grubbs' test\nWe've now checked that the data are normal. Now let's apply Grubbs' outlier test!\n\nGrubbs' test assesses whether the value that is farthest from the mean is an outlier - the value could be either the maximum or minimum value. The test is performed using the grubbs.test() function from the outliers package:\n\ngrubbs.test(x)\n\nx is the input data as a numeric vector\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply Grubbs' test to the river nitrate data\ngrubbs.test(river$nitrate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tGrubbs test for one outlier\n\ndata:  river$nitrate\nG = 4.72676, U = 0.92269, p-value = 0.000211\nalternative hypothesis: highest value 1.897 is an outlier\n```\n:::\n:::\n\n\n- *You can now use Grubbs' test to check for single outliers. Remember, the lower the p-value returned by the test, the higher the likelihood that the point tested was an outlier.*\n\n### Hunting multiple outliers using Grubbs' test\nGrubbs' test found that the maximum value could be an outlier, but what if there are more? Further outliers can be found by repeating Grubbs' test, after removing any previously identified outliers from the data.\n\nTo identify the point that was tested, the which.min() or which.max() functions can be used to find the index containing the largest or smallest value - remember we know which of these it is from the Grubbs' test output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply Grubbs' test to the nitrate data\ngrubbs.test(river$nitrate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tGrubbs test for one outlier\n\ndata:  river$nitrate\nG = 4.72676, U = 0.92269, p-value = 0.000211\nalternative hypothesis: highest value 1.897 is an outlier\n```\n:::\n\n```{.r .cell-code}\n# Use which.max to find row index of the max\nwhich.max(river$nitrate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 156\n```\n:::\n\n```{.r .cell-code}\n# Runs Grubbs' test excluding row 156\ngrubbs.test(river$nitrate[-156])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tGrubbs test for one outlier\n\ndata:  river$nitrate[-156]\nG = 3.42983, U = 0.95915, p-value = 0.07756\nalternative hypothesis: highest value 1.643 is an outlier\n```\n:::\n\n```{.r .cell-code}\n# Print the value tested in the second Grubbs' test\nmax(river$nitrate[-156])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.643\n```\n:::\n:::\n\n\n\n### Visual assessment of seasonality\nThe first step when analyzing time series should be to construct graphical summaries that provide insight into important features such as trend, seasonality and possible anomalies. In this exercise, you'll use several plots to explore thenitrate concentrations as a time series and to identify the period of any seasonal patterns that might be present.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View contents of dataset\nhead(river)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nitrate   months index\n1:   1.581  January     1\n2:   1.323 February     2\n3:   1.140    March     3\n4:   1.245    April     4\n5:   1.072      May     5\n6:   1.483     June     6\n```\n:::\n\n```{.r .cell-code}\n# Show the time series of nitrate concentrations with time\nplot(nitrate ~ index, data = river, type = \"o\")\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-5-1.png){width=1800}\n:::\n\n```{.r .cell-code}\n# Create a boxplot of nitrate against months\nboxplot(nitrate~months, data = river)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-5-2.png){width=1800}\n:::\n:::\n\n\n#### Plot the monthly means\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the mean nitrate by month\nmonthly_mean <- tapply(river$nitrate, river$months, FUN = mean)\nmonthly_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    April    August  December  February   January      July      June     March \n1.0166250 0.9380833 1.2264167 1.1838400 1.2163600 0.9810417 0.9792083 1.1050400 \n      May  November   October September \n0.9978333 1.0962500 1.0360000 0.9885833 \n```\n:::\n\n```{.r .cell-code}\n# Plot the monthly means \nplot(monthly_mean, type = \"o\", xlab = \"Month\", ylab = \"Monthly mean\")\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-6-1.png){width=1800}\n:::\n:::\n\n\n#### Create a boxplot of nitrate against months\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a boxplot of nitrate against months\nboxplot(nitrate~months, data = river)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-7-1.png){width=1800}\n:::\n:::\n\n\n### Seasonal Hybrid ESD algorithm\nYou've identified a repeating seasonal cycle in the nitrate data, with a period of 12 months. You are now ready to apply the Seasonal-Hybrid ESD algorithm to find out if there are anomalies present in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run Seasonal-Hybrid ESD for nitrate concentrations\nAnomalyDetectionVec(river$nitrate,\n                    period = 12, \n                    direction = 'both', \n                    plot = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$anoms\n  index anoms\n1     6 1.483\n2    53 1.533\n3   156 1.897\n\n$plot\n```\n:::\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-8-1.png){width=1800}\n:::\n:::\n\n\n### Interpreting Seasonal-Hybrid ESD output\nThe Seasonal-Hybrid ESD algorithm provides some useful output for understanding where the anomalies occur within the data.\n\nIn particular, the AnomalyDetectionVec() function generates output as a list with the two elements\n\n$anoms, a data frame containing the columns index and anoms\n$plot a plot of the time series with anomalies highlighted (if plot = T)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use Seasonal-Hybrid ESD for nitrate concentrations\nriver_anomalies <- AnomalyDetectionVec(x = river$nitrate, period = 12, direction = 'both', plot = T)\n\n# Print the anomalies\nriver_anomalies$anoms\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  index anoms\n1     6 1.483\n2    53 1.533\n3   156 1.897\n```\n:::\n\n```{.r .cell-code}\n# Print the plot\nprint(river_anomalies$plot)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-9-1.png){width=1800}\n:::\n:::\n\n\n\n#### Seasonal-Hybrid ESD versus Grubbs' test\nRecall when using Grubbs' test on the river nitrate data, that only row 156 was found to be anomalous, while Seasonal-Hybrid ESD identified 2 further high-valued anomalies. Which of the following provides the best explanation for the difference between the two approaches?\n\n- *Spot on! Grubbs' test can only take an extreme value as a candidate for an outlier, while Seasonal-Hybrid ESD explicitly accounts for the repeating seasonal patterns. Therefore, it is likely that the extra anomalies have been identified as extreme with respect to the seasonal pattern in the data.*\n\n## Distance and density based anomaly detection\n\n### Exploring wine\nThroughout this chapter, you'll explore techniques for anomaly detection with a new data set called wine. Each row of this data set refers to a wine whose chemical composition is described by two numeric fields:\n\npH: how acidic the wine is\nalcohol: the wine's alcohol content (%)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwine <- fread(\"data/wine.csv\")\nwine <- wine[, .(pH, alcohol)]\n# View the contents of the wine data\nhead(wine)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     pH alcohol\n1: 3.00     8.8\n2: 3.30     9.5\n3: 3.26    10.1\n4: 3.19     9.9\n5: 3.19     9.9\n6: 3.26    10.1\n```\n:::\n\n```{.r .cell-code}\n# Scatterplot of wine pH against alcohol\nplot(pH ~ alcohol, data = wine)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-10-1.png){width=1800}\n:::\n:::\n\n\n\n### kNN distance matrix\nThe kNN distance matrix is a necessary prior step to producing the kNN distance score. The distance matrix has\n\n rows, where  is the number of data points\n columns, where  is the user-chosen number of neighbors.\nThe entry in row i and column j of the distance matrix is the distance between point i and its jth nearest neighbor.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the 5 nearest neighbors distance\nwine_nn <- get.knn(wine, k = 5)\n\n# View the distance matrix\nhead(wine_nn$nn.dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    0    0\n[2,]    0    0    0    0    0\n[3,]    0    0    0    0    0\n[4,]    0    0    0    0    0\n[5,]    0    0    0    0    0\n[6,]    0    0    0    0    0\n```\n:::\n\n```{.r .cell-code}\n# Distance from wine 5 to nearest neighbor\nwine_nn$nn.dist[5, 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\n# Row index of wine 5's nearest neighbor \nrow_idx = wine_nn$nn.ind[5, 1]\nrow_idx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9800\n```\n:::\n\n```{.r .cell-code}\n# Return data for wine 5 and its nearest neighbor\nwine[c(5, row_idx), ] %>% data_table()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-cc4231d90c097733270d\" style=\"width:100%;height:auto;\" class=\"datatables html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-cc4231d90c097733270d\">{\"x\":{\"style\":\"bootstrap4\",\"filter\":\"none\",\"vertical\":false,\"data\":[[3.19,3.19],[9.9,9.9]],\"container\":\"<table class=\\\"table table-bordered table-striped\\\">\\n  <thead>\\n    <tr>\\n      <th>pH<\\/th>\\n      <th>alcohol<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"scrollX\":true,\"columnDefs\":[{\"className\":\"dt-center\",\"targets\":[1,2]},{\"className\":\"dt-right\",\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n### kNN distance score\nOnce the kNN distance matrix is available, the nearest neighbor distance score can be calculated by averaging the nearest neighbor distances for each point.\n\nLarge values of the distance score can be interpreted as indicating the presence of unusual or anomalous points.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the 5 nearest neighbors distance\nwine_nn <- get.knn(wine, k = 5)\n\n# Create score by averaging distances\nwine_nnd <- rowMeans(wine_nn$nn.dist)\nhist(wine_nnd)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-12-1.png){width=1800}\n:::\n\n```{.r .cell-code}\n# Print row index of the most anomalous point\nwhich.max(wine_nnd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3919\n```\n:::\n:::\n\n\n\n### Standardizing features\nIt is important to ensure that the feature inputs to the kNN distance calculation are standardized using the scale() function. Standardization ensures that features with large mean or variance do not disproportionately influence the kNN distance score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Without standardization, features have different scales\nsummary(wine)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       pH           alcohol     \n Min.   :2.720   Min.   : 8.00  \n 1st Qu.:3.090   1st Qu.: 9.50  \n Median :3.180   Median :10.40  \n Mean   :3.188   Mean   :10.51  \n 3rd Qu.:3.280   3rd Qu.:11.40  \n Max.   :3.820   Max.   :14.20  \n```\n:::\n\n```{.r .cell-code}\n# Standardize the wine columns\nwine_scaled <- scale(wine)\n\n# Standardized features have similar means and quartiles\nsummary(wine_scaled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       pH              alcohol        \n Min.   :-3.10130   Min.   :-2.04323  \n 1st Qu.:-0.65081   1st Qu.:-0.82425  \n Median :-0.05475   Median :-0.09286  \n Mean   : 0.00000   Mean   : 0.00000  \n 3rd Qu.: 0.60755   3rd Qu.: 0.71979  \n Max.   : 4.18393   Max.   : 2.99522  \n```\n:::\n:::\n\n\n### Appending the kNN score\nNow you've standardized your input features, it's time to create the kNN distance score for the standardized wine data and append it as a new column.\n\nIn this exercise, the 5 nearest neighbor distance score is already available in the object wine_nnd. So that the score is easily available for visualization or further analysis, you'll append the score as a new column to the unstandardized data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the 5 nearest neighbors distance\nwine_nn <- get.knn(wine_scaled, k = 5)\n\n# Create score by averaging distances\nwine_nnd <- rowMeans(wine_nn$nn.dist)\n\n# Print the 5-nearest neighbor distance score\nwine_nnd[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0 0 0 0 0\n```\n:::\n\n```{.r .cell-code}\n# Append the score as a new column \nwine$score <- wine_nnd\n```\n:::\n\n\n### Visualizing kNN distance score\nThe kNN distance score can be hard to interpret by simply eyeballing a set of values. It's helpful to use scatterplots to visualize the kNN distance score to understand how the score works. When interpreting the plot, the relative size of the kNN distance score is more informative than the absolute value.\n\nThe wine data has been loaded with the kNN distance score appended from the previous exercise.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot showing pH, alcohol and kNN score\nplot(pH ~ alcohol, data = wine, cex = sqrt(score), pch = 20)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-15-1.png){width=1800}\n:::\n:::\n\n\n### LOF calculation\nkNN is useful for finding global anomalies, but is less able to surface local outliers. In this exercise, you'll practice using the lof() function to calculate local outlier factors for the wine data.\n\nlof() has the arguments:\n\nx: the data for scoring,\nk: the number of neighbors used to calculate the LOF.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dbscan)\n# Calculate the LOF for wine data\nwine_lof <- lof(scale(wine), 5)\n\n# Append the LOF score as a new column\nwine$score <- wine_lof\n```\n:::\n\n\n\n### LOF visualization\nAs with kNN distance scoring, a scatterplot can be a useful visual aid for understanding why a low or high score has been assigned. In this exercise, the LOF score is visualized by scaling the points according to the size of the score. You should notice some differences in the location of points with highest scores compared to kNN distance.\n\nThe wine data for this exercise already contains the score column appended in the previous exercise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot showing pH, alcohol and LOF score\nplot(pH ~ alcohol, data = wine, pch = 20, cex = sqrt(score))\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-17-1.png){width=1800}\n:::\n:::\n\n\n### LOF vs kNN\nIt is common to look first at the points with highest anomaly scores before taking any action. When several algorithms are used, the points with highest scores may differ.\n\nIn this final exercise, you'll calculate new LOF and kNN distance scores for the wine data, and print the highest scoring point for each.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scaled wine data\n#wine_scaled <- scale(wine)\n\n# Calculate and append kNN distance as a new column\nwine_nn <- get.knn(wine_scaled, k = 10)\nwine$score_knn <- rowMeans(wine_nn$nn.dist)     \n\n# Calculate and append LOF as a new column\nwine$score_lof <- lof(wine_scaled, k = 10)\n\n# Find the row location of highest kNN\nwhich.max(wine$score_knn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2957\n```\n:::\n\n```{.r .cell-code}\n# Find the row location of highest LOF\nwhich.max(wine$score_lof)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 15\n```\n:::\n:::\n\n\n## Isolation forest\n\n### Fit and predict with an isolation tree\nThe two most important functions to know when fitting an isolation tree are iForest() to fit and predict() to generate an isolation score. In this exercise, you'll use these two functions to explore isolated points in the wine data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(isofor)\n# Build an isolation tree \nwine_tree <- iForest(wine_scaled, nt = 1)\n\n# Create isolation score\nwine$tree_score <- predict(wine_tree, newdata = wine_scaled) \n\n# Histogram plot of the scores\n\nhist(wine$tree_score, breaks = 40)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-19-1.png){width=1800}\n:::\n:::\n\n\n- Isolation forest scores are values between 0 and 1. High scores near to 1 indicate possible anomalies, while scores between 0 and 0.5 do not.\n\n\n### Fit an isolation forest\nAn isolation forest is a collection of isolation trees, and uses exactly the same commands that you used in the previous lesson to grow a single isolation tree. In this exercise, you'll practice fitting an isolation forest to the wine data.\n\nWhen growing an isolation forest you should to pay particular attention to the number of trees and the number of points sampled to grow each tree.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit isolation forest\nwine_forest <- iForest(wine, nt = 100, phi = 200)\n\n# Create isolation score from forest\nwine_score <- predict(wine_forest, newdata = wine)\n\n# Append score to the wine data\nwine$score <- wine_score\n```\n:::\n\n\n\n### Checking convergence\nThe anomaly score from an isolation forest usually don't change after a certain number of trees have been grown. This is called convergence, and can be checked by comparing the scores generated by forests with different numbers of trees. If the scores differ greatly, then this might suggest that more trees are required.\n\nIn this exercise, the scores for isolation forests with different numbers of trees have been already calculated for you and are contained in the data frame wine_scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwine <- fread(\"data/wine.csv\")\nwine <- wine[, .(pH, alcohol)]\n# View the contents of the wine scores\n# Fit isolation forest\nwine_forest_2000 <- iForest(wine, nt = 200, phi = 200)\ntrees_2000 <- predict(wine_forest_2000, newdata = wine)\n\nwine_forest_1000 <- iForest(wine, nt = 100, phi = 200)\n\ntrees_1000 <- predict(wine_forest_1000, newdata = wine)\nwine_scores <-  data.frame(trees_2000,  trees_1000)\nhead(wine_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  trees_2000 trees_1000\n1  0.5302965  0.5414763\n2  0.4509511  0.4434861\n3  0.4434579  0.4403694\n4  0.4336313  0.4255291\n5  0.4336313  0.4255291\n6  0.4434579  0.4403694\n```\n:::\n\n```{.r .cell-code}\n# Score scatterplot 2000 vs 1000 trees \nplot(trees_2000 ~ trees_1000, data = wine_scores)\n\n# Add reference line of equality\nabline(a = 0, b = 1)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-21-1.png){width=1800}\n:::\n:::\n\n\n### A grid of points\nIn the video, you saw how it can be instructive to use a contour plot over a grid of points to see what the anomaly score might have been at locations other than where the data occurred.\n\nIn this exercise you'll create and visualize a grid of points across the region of interest. The grid you create will be used in the exercise that follows to visualize predicted isolation scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sequence of values for pH and alcohol\nph_seq <- seq(min(wine$pH), max(wine$pH), length.out = 25)\nalcohol_seq <- seq(min(wine$alcohol),  max(wine$alcohol), length.out = 25)\n\n# Create a data frame of grid coordinates\nwine_grid <- expand.grid(pH = ph_seq, alcohol = alcohol_seq)\n\n# Visualise the grid using a scatterplot\nplot(pH~alcohol, data = wine_grid, pch = 20)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-22-1.png){width=1800}\n:::\n:::\n\n\n\n### Prediction over a grid\nIn this exercise, you'll use an isolation forest to obtain an anomaly score for the grid of points you created in the last exercise. Getting the anomaly score is the final preparatory step required to visualize the isolation scores.\n\nThe data frame wine_grid and fitted isolation forest wine_forest from the previous exercise are preloaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate isolation score at grid locations\nwine_grid$score <- predict(wine_forest_2000, wine_grid)\n```\n:::\n\n\n### Anomaly contours\nYou now have the key ingredients to produce a contour plot, which is a powerful tool for viewing how the anomaly score varies across the region spanned by the data points.\n\nThe wine_grid data from the previous exercise has been preloaded for you to use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lattice)\n# Contour plot of isolation scores\ncontourplot(score ~ pH + alcohol, wine_grid, region = TRUE)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-24-1.png){width=1800}\n:::\n:::\n\n\n\n## Comparing performance\n\n### Thyroid data\nIn this chapter, you'll explore a new data set called thyroid. These data contain examples of thyroid hormone measurements for 1000 patients, and a column called label indicating the presence of thyroid disease. It is expected that unusual hormone measurements can be used to detect disease.\n\nThe overall goal is to determine whether an anomaly score based on hormone measurements could be used to detect thyroid disease. In this exercise, you'll use plotting techniques to visually assess the distribution of thyroid disease.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthyroid <- fread(\"data/thyroid.csv\")\n# View contents of thryoid data\nhead(thyroid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   label        TSH        T3       TT4       T4U        FTI       TBG\n1:     0 -0.2559334 -6.783703 -1.983614 -1.288439 -1.2181574 -1.443646\n2:     0 -1.3971053 -7.659171 -1.273372 -1.110363 -0.6250937 -1.750020\n3:     0 -0.7039581 -5.631023 -1.500762 -1.453953 -0.6427933 -2.082726\n4:     0 -0.3894648 -6.378238 -1.854402 -1.741635 -1.0986123 -1.994618\n5:     0 -1.4415570 -7.659171 -1.419084 -1.139142 -1.0986123 -1.396179\n6:     0 -0.3130918 -7.659171 -1.916923 -1.628306 -1.4294665 -1.617668\n```\n:::\n\n```{.r .cell-code}\n# Tabulate the labels\ntable(thyroid$label)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  0   1 \n978  22 \n```\n:::\n\n```{.r .cell-code}\n# Proportion of thyroid cases\nprop_disease <- 22/(978+22)\n```\n:::\n\n\n\n### Visualizing thyroid disease\nIn previous chapters, we considered data with two or fewer features. As the number of features increases, it becomes harder to visually assess whether individual points are anomalous.\n\nIn cases where anomaly labels are available, it is important to use scatterplots to visualize how the distribution of anomalies varies with different combinations of features.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot showing TT4, TBG and anomaly labels\nplot(TT4 ~ TBG, data = thyroid, pch = 20, col = label + 1)\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-26-1.png){width=1800}\n:::\n:::\n\n\n- *The disease cases seem to occur at extreme values of the hormone measurements. Next you'll build an anomaly score to capture this!*\n\n### Anomaly score\nYour visualization suggested that thyroid disease could be detected from anomalous hormone measurements.\n\nIn this exercise you'll use an isolation forest to generate an anomaly score for thyroid levels, and compare the resulting score against the true disease status.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit isolation forest\nthyroid_xdf <- thyroid[, .SD, .SDcols = !\"label\"]\nthyroid_forest <- iForest(thyroid[, .SD, .SDcols = !\"label\"], nt = 200, phi = 100)\n\n# Anomaly score \nthyroid$iso_score <- predict(thyroid_forest, thyroid[, -1])\n\n# Boxplot of the anomaly score against labels\nboxplot(iso_score ~ label, data = thyroid, col = \"olivedrab4\")\n```\n\n::: {.cell-output-display}\n![](anomaly_detection_files/figure-html/unnamed-chunk-27-1.png){width=1800}\n:::\n:::\n\n\n- *The boxplot showed that the anomaly scores were generally higher for the thyroid disease cases. This adds further weight to the claim that the disease cases could be detected from anomalous hormone levels.*\n\n### Binarized scores\nIt's worthwhile to compare the performance of more than one anomaly detection algorithm before deciding which to use.\n\nIn this exercise, you'll construct a pair of binary anomaly scores based on local outlier factor (LOF) and the isolation forest. The isolation score vector iso_score generated in the previous exercise is preloaded for you to use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\niso_score <- thyroid$iso_score\n# Scale the measurement columns of thyroid\nscaled_thyroid_measurements <- scale(thyroid_xdf)\n\n# Create a LOF score for the measurements\nlof_score <- lof(scaled_thyroid_measurements, k = 10)\n                 \n# Calculate high threshold for lof_score\nhigh_lof <- quantile(lof_score, probs = 0.98) \n\n# Append binary LOF score to thyroid data\nthyroid$binary_lof <- as.numeric(lof_score >= high_lof)\n                 \n# Calculate high threshold for iso_score\nhigh_iso <- quantile(iso_score, probs = 0.98)  \n\n# Append binary isolation score to thyroid data\nthyroid$binary_iso <- as.numeric(iso_score> high_iso )         \n```\n:::\n\n\n- *Although the 98th percentile was chosen here, other thresholds could have been used. The choice might be constrained by the number of potential anomalies you have time to check, or the cost of missing an anomaly.*\n\n\n### Cross-tabulate binary scores\nThe table() function tallies the number of occurrences of combinations of values across one or more vectors. The orientation of the output table depends on the order that the input vectors are specified. For example in the table\n\ntable(currency, country)\n\n        country\ncurrency UK USA\n       $  0   1\n       £  1   0\nthe rows are indexed by currency because this appears first in the table() function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tabulate agreement of label and binary isolation score \ntable(thyroid$label, thyroid$binary_iso)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n      0   1\n  0 971   7\n  1   9  13\n```\n:::\n\n```{.r .cell-code}\n# Tabulate agreement of label and binary LOF score \ntable(thyroid$label, thyroid$binary_lof)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n      0   1\n  0 958  20\n  1  22   0\n```\n:::\n\n```{.r .cell-code}\n# Proportion of binary_iso and label that agree\niso_prop <- mean(thyroid$label == thyroid$binary_iso)\n\n# Proportion of binary_lof and label that agree\nlof_prop <- mean(thyroid$label == thyroid$binary_lof)\n```\n:::\n\n\n- *Although the measure of agreement is intuitive, it can be misleadingly high when anomalies are very rare. In the next exercise, you'll try other ways to quantify the success of the algorithm.*\n\n### Thyroid precision and recall\nCross-tabulating the agreement between a binary score and a known label is a great way to understand how well the algorithm performs. Precision and recall are two further measures based on the table that give more insight into how well the score performs.\n\nIn this exercise, you'll explore precision and recall using the thyroid data. The binary_lof and binary_iso scores created in the previous exercises are available to use as columns in the thyroid data. The code used to tabulate agreements in the previous exercise is also included.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tabulation for the binary isolation score\ntable(thyroid$label, thyroid$binary_iso)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n      0   1\n  0 971   7\n  1   9  13\n```\n:::\n\n```{.r .cell-code}\n# Precision for the isolation score\nprecision_iso <- 12 / (8 + 12)\n# Recall for the isolation score\nrecall_iso <- 12 / (10+12)\n\n# Tabulation for the binary lof score\ntable(thyroid$label, thyroid$binary_lof)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n      0   1\n  0 958  20\n  1  22   0\n```\n:::\n\n```{.r .cell-code}\n# Precision for the binary lof score\nprecision_lof <- 0 / (20 + 0)\n# Recall for the binary lof score\nrecall_lof <- 0 / (22+0)\n```\n:::\n\n\n### Converting character to factor\nBoth LOF and isolation forest can be trained using data containing categorical features, but it's easier if these are converted to factors first.\n\nIn this exercise, you'll revisit the thyroid data which contains some additional categorical features that will need to be converted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print the column classes in thyroid\nsapply(X = thyroid, FUN = class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     label        TSH         T3        TT4        T4U        FTI        TBG \n \"integer\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\" \n iso_score binary_lof binary_iso \n \"numeric\"  \"numeric\"  \"numeric\" \n```\n:::\n\n```{.r .cell-code}\n# Convert column with character class to factor\nthyroid$age <- as.factor(thyroid$age)\nthyroid$sex <- as.factor(thyroid$sex)\n\n# Check that all columns are factor or numeric\nsapply(X = thyroid, FUN = class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     label        TSH         T3        TT4        T4U        FTI        TBG \n \"integer\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\" \n iso_score binary_lof binary_iso        age        sex \n \"numeric\"  \"numeric\"  \"numeric\"   \"factor\"   \"factor\" \n```\n:::\n:::\n\n\n\n### Isolation forest with factors\nAs you saw in the video, an isolation forest can accept categorical features as input, but only if they are encoded as factor variables.\n\nIn this exercise, the thyroid data you edited in the previous exercise is preloaded. To be extra careful, you should first check that all of the features are numeric or factor before attempting to train an isolation forest.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the class of age column\nclass(thyroid$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n\n```{.r .cell-code}\n# Check the class of sex column\nclass(thyroid$sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n\n```{.r .cell-code}\n# Fit an isolation forest with 100 trees\nthyroid_for <- iForest(thyroid[,-1], 100)\n```\n:::\n\n\n- *Being able to incorporate categorical features greatly extends the range of applications in which isolation forests can be used.*\n\n### LOF with factors\nThe lof() function can accept either a numeric data frame or a distance matrix as input to calculate LOF scores. In this exercise, you'll practice calculating a distance matrix using Gower's distance, which can then be passed to the lof() function for scoring.\n\nAs in the previous exercise, the thyroid data with character columns converted to factors has been preloaded for you to use.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate Gower's distance matrix\nlibrary(cluster)\nthyroid_dist <- daisy(thyroid[, -1], metric = \"gower\")\n\n# Generate LOF scores for thyroid data\nthyroid_lof <- lof(thyroid_dist, k = 10)\n\n# Range of values in the distance matrix\nrange(as.matrix(thyroid_dist))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0000000 0.7039034\n```\n:::\n:::\n",
    "supporting": [
      "anomaly_detection_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<link href=\"../../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/datatables-binding-0.22/datatables.js\"></script>\n<script src=\"../../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../../../site_libs/dt-core-bootstrap4-1.11.3/css/dataTables.bootstrap4.min.css\" rel=\"stylesheet\" />\n<link href=\"../../../site_libs/dt-core-bootstrap4-1.11.3/css/dataTables.bootstrap4.extra.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/dt-core-bootstrap4-1.11.3/js/jquery.dataTables.min.js\"></script>\n<script src=\"../../../site_libs/dt-core-bootstrap4-1.11.3/js/dataTables.bootstrap4.min.js\"></script>\n<link href=\"../../../site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}